/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Serving Flask app 'node8'
 * Debug mode: on
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://localhost:8008
[33mPress CTRL+C to quit[0m
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
127.0.0.1 - - [28/Jul/2025 14:27:04] "GET /train/ HTTP/1.1" 200 -
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]Finding best initial lr:   1%|          | 1/100 [00:01<02:00,  1.22s/it]Finding best initial lr:   2%|â–         | 2/100 [00:01<01:16,  1.28it/s]Finding best initial lr:   3%|â–Ž         | 3/100 [00:02<01:01,  1.57it/s]Finding best initial lr:   4%|â–         | 4/100 [00:02<00:55,  1.74it/s]Finding best initial lr:   5%|â–Œ         | 5/100 [00:03<00:50,  1.88it/s]Finding best initial lr:   6%|â–Œ         | 6/100 [00:03<00:48,  1.93it/s]Finding best initial lr:   7%|â–‹         | 7/100 [00:04<00:48,  1.93it/s]Finding best initial lr:   8%|â–Š         | 8/100 [00:04<00:48,  1.91it/s]Finding best initial lr:   9%|â–‰         | 9/100 [00:05<00:46,  1.95it/s]Finding best initial lr:  10%|â–ˆ         | 10/100 [00:05<00:46,  1.95it/s]Finding best initial lr:  11%|â–ˆ         | 11/100 [00:06<00:44,  1.99it/s]Finding best initial lr:  12%|â–ˆâ–        | 12/100 [00:06<00:43,  2.04it/s]Finding best initial lr:  13%|â–ˆâ–Ž        | 13/100 [00:07<00:42,  2.07it/s]Finding best initial lr:  14%|â–ˆâ–        | 14/100 [00:07<00:42,  2.02it/s]Finding best initial lr:  15%|â–ˆâ–Œ        | 15/100 [00:08<00:45,  1.86it/s]Finding best initial lr:  16%|â–ˆâ–Œ        | 16/100 [00:08<00:43,  1.92it/s]Finding best initial lr:  17%|â–ˆâ–‹        | 17/100 [00:09<00:41,  1.99it/s]Finding best initial lr:  18%|â–ˆâ–Š        | 18/100 [00:09<00:40,  2.02it/s]Finding best initial lr:  19%|â–ˆâ–‰        | 19/100 [00:10<00:39,  2.03it/s]Finding best initial lr:  20%|â–ˆâ–ˆ        | 20/100 [00:10<00:39,  2.02it/s]Finding best initial lr:  21%|â–ˆâ–ˆ        | 21/100 [00:11<00:38,  2.04it/s]Finding best initial lr:  22%|â–ˆâ–ˆâ–       | 22/100 [00:11<00:38,  2.02it/s]Finding best initial lr:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:12<00:38,  1.99it/s]Finding best initial lr:  24%|â–ˆâ–ˆâ–       | 24/100 [00:12<00:38,  2.00it/s]Finding best initial lr:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:13<00:38,  1.95it/s]Finding best initial lr:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:13<00:37,  1.95it/s]Finding best initial lr:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:14<00:36,  1.99it/s]Finding best initial lr:  28%|â–ˆâ–ˆâ–Š       | 28/100 [00:14<00:36,  1.96it/s]Finding best initial lr:  29%|â–ˆâ–ˆâ–‰       | 29/100 [00:15<00:36,  1.95it/s]Finding best initial lr:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:15<00:36,  1.92it/s]Finding best initial lr:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:16<00:35,  1.96it/s]Finding best initial lr:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:16<00:33,  2.01it/s]Finding best initial lr:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:17<00:32,  2.05it/s]Finding best initial lr:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:17<00:31,  2.10it/s]Finding best initial lr:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:18<00:30,  2.10it/s]Finding best initial lr:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:18<00:30,  2.12it/s]Finding best initial lr:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:19<00:29,  2.12it/s]Finding best initial lr:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:19<00:29,  2.10it/s]Finding best initial lr:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:19<00:29,  2.07it/s]Finding best initial lr:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:20<00:29,  2.07it/s]Finding best initial lr:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:20<00:28,  2.04it/s]Finding best initial lr:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:21<00:27,  2.07it/s]Finding best initial lr:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:21<00:26,  2.11it/s]Finding best initial lr:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:22<00:26,  2.13it/s]Finding best initial lr:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:22<00:25,  2.15it/s]Finding best initial lr:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:23<00:24,  2.16it/s]Finding best initial lr:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:23<00:24,  2.12it/s]Finding best initial lr:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:24<00:25,  2.08it/s]Finding best initial lr:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:24<00:24,  2.10it/s]Finding best initial lr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:25<00:23,  2.10it/s]Finding best initial lr:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:26<00:34,  1.42it/s]Finding best initial lr:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:26<00:30,  1.56it/s]Finding best initial lr:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:27<00:28,  1.68it/s]Finding best initial lr:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:27<00:25,  1.77it/s]Finding best initial lr:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:28<00:24,  1.83it/s]Finding best initial lr:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:28<00:22,  1.92it/s]Finding best initial lr:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:29<00:21,  2.00it/s]Finding best initial lr:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:29<00:20,  2.06it/s]Finding best initial lr:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:30<00:19,  2.08it/s]Finding best initial lr:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:30<00:19,  2.06it/s]Finding best initial lr:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:31<00:18,  2.08it/s]Finding best initial lr:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:31<00:18,  2.06it/s]Finding best initial lr:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:32<00:17,  2.07it/s]Finding best initial lr:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:32<00:17,  2.09it/s]Finding best initial lr:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:33<00:16,  2.14it/s]Finding best initial lr:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:33<00:15,  2.14it/s]Finding best initial lr:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:34<00:15,  2.17it/s]Finding best initial lr:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:34<00:14,  2.19it/s]Finding best initial lr:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:34<00:14,  2.14it/s]Finding best initial lr:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:35<00:14,  2.13it/s]Finding best initial lr:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:35<00:14,  2.07it/s]Finding best initial lr:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:36<00:13,  2.08it/s]Finding best initial lr:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:36<00:13,  2.04it/s]Finding best initial lr:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:37<00:12,  2.08it/s]Finding best initial lr:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:37<00:11,  2.12it/s]Finding best initial lr:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:38<00:11,  2.16it/s]Finding best initial lr:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:38<00:10,  2.17it/s]Finding best initial lr:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:39<00:10,  2.14it/s]Finding best initial lr:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:39<00:09,  2.11it/s]Finding best initial lr:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [00:40<00:09,  2.09it/s]Finding best initial lr:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:40<00:09,  2.06it/s]Finding best initial lr:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:41<00:08,  2.05it/s]Finding best initial lr:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [00:41<00:08,  2.07it/s]Finding best initial lr:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:42<00:07,  2.06it/s]Finding best initial lr:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:42<00:07,  2.10it/s]Finding best initial lr:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [00:43<00:06,  2.11it/s]Finding best initial lr:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:43<00:06,  2.15it/s]Finding best initial lr:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [00:43<00:06,  2.00it/s]
LR finder stopped early after 87 steps due to diverging loss.
Learning rate set to 2.137962089502232e-05
Restoring states from the checkpoint path at /home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/.lr_find_03cc6786-cf62-4bcd-94d8-e7c9000fee17.ckpt
Restored all states from the checkpoint at /home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/.lr_find_03cc6786-cf62-4bcd-94d8-e7c9000fee17.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name                               | Type                            | Params | Mode 
------------------------------------------------------------------------------------------------
0  | loss                               | MultiLoss                       | 0      | train
1  | logging_metrics                    | ModuleList                      | 0      | train
2  | input_embeddings                   | MultiEmbedding                  | 570    | train
3  | prescalers                         | ModuleDict                      | 240    | train
4  | static_variable_selection          | VariableSelectionNetwork        | 6.7 K  | train
5  | encoder_variable_selection         | VariableSelectionNetwork        | 3.7 K  | train
6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.6 K  | train
7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train
8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train
9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train
10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train
11 | lstm_encoder                       | LSTM                            | 2.2 K  | train
12 | lstm_decoder                       | LSTM                            | 2.2 K  | train
13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train
14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train
15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train
16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K  | train
17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train
18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train
19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train
20 | output_layer                       | ModuleList                      | 51     | train
------------------------------------------------------------------------------------------------
26.7 K    Trainable params
0         Non-trainable params
26.7 K    Total params
0.107     Total estimated model params size (MB)
443       Modules in train mode
0         Modules in eval mode
Sanity Checking: |          | 0/? [00:00<?, ?it/s]/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]                                                                           /home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/50 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s] Epoch 0:   2%|â–         | 1/50 [00:00<00:25,  1.96it/s]Epoch 0:   2%|â–         | 1/50 [00:00<00:25,  1.96it/s, v_num=4, train_loss_step=1.91e+3]Epoch 0:   4%|â–         | 2/50 [00:01<00:24,  1.98it/s, v_num=4, train_loss_step=1.91e+3]Epoch 0:   4%|â–         | 2/50 [00:01<00:24,  1.98it/s, v_num=4, train_loss_step=3.72e+3]Epoch 0:   6%|â–Œ         | 3/50 [00:01<00:23,  2.00it/s, v_num=4, train_loss_step=3.72e+3]Epoch 0:   6%|â–Œ         | 3/50 [00:01<00:23,  1.99it/s, v_num=4, train_loss_step=4e+3]   Epoch 0:   8%|â–Š         | 4/50 [00:01<00:22,  2.02it/s, v_num=4, train_loss_step=4e+3]Epoch 0:   8%|â–Š         | 4/50 [00:01<00:22,  2.02it/s, v_num=4, train_loss_step=3.06e+3]Epoch 0:  10%|â–ˆ         | 5/50 [00:02<00:22,  2.03it/s, v_num=4, train_loss_step=3.06e+3]Epoch 0:  10%|â–ˆ         | 5/50 [00:02<00:22,  2.03it/s, v_num=4, train_loss_step=3.07e+3]Epoch 0:  12%|â–ˆâ–        | 6/50 [00:02<00:21,  2.03it/s, v_num=4, train_loss_step=3.07e+3]Epoch 0:  12%|â–ˆâ–        | 6/50 [00:02<00:21,  2.03it/s, v_num=4, train_loss_step=2.51e+3]Epoch 0:  14%|â–ˆâ–        | 7/50 [00:03<00:21,  2.00it/s, v_num=4, train_loss_step=2.51e+3]Epoch 0:  14%|â–ˆâ–        | 7/50 [00:03<00:21,  2.00it/s, v_num=4, train_loss_step=2.81e+3]Epoch 0:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:20,  2.01it/s, v_num=4, train_loss_step=2.81e+3]Epoch 0:  16%|â–ˆâ–Œ        | 8/50 [00:04<00:21,  1.99it/s, v_num=4, train_loss_step=2.88e+3]Epoch 0:  18%|â–ˆâ–Š        | 9/50 [00:04<00:20,  2.00it/s, v_num=4, train_loss_step=2.88e+3]Epoch 0:  18%|â–ˆâ–Š        | 9/50 [00:04<00:20,  2.00it/s, v_num=4, train_loss_step=2.45e+3]Epoch 0:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:19,  2.01it/s, v_num=4, train_loss_step=2.45e+3]Epoch 0:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:19,  2.01it/s, v_num=4, train_loss_step=3.36e+3]Epoch 0:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:19,  2.02it/s, v_num=4, train_loss_step=3.36e+3]Epoch 0:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:19,  2.02it/s, v_num=4, train_loss_step=2.82e+3]Epoch 0:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:18,  2.03it/s, v_num=4, train_loss_step=2.82e+3]Epoch 0:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:18,  2.03it/s, v_num=4, train_loss_step=2.46e+3]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:18,  2.03it/s, v_num=4, train_loss_step=2.46e+3]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:18,  2.03it/s, v_num=4, train_loss_step=2.36e+3]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:17,  2.02it/s, v_num=4, train_loss_step=2.36e+3]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:17,  2.02it/s, v_num=4, train_loss_step=3.64e+3]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:17,  1.99it/s, v_num=4, train_loss_step=3.64e+3]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:17,  1.99it/s, v_num=4, train_loss_step=3.27e+3]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:08<00:17,  1.99it/s, v_num=4, train_loss_step=3.27e+3]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:08<00:17,  1.98it/s, v_num=4, train_loss_step=2.32e+3]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:16,  1.97it/s, v_num=4, train_loss_step=2.32e+3]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:16,  1.96it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:09<00:16,  1.96it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:09<00:16,  1.96it/s, v_num=4, train_loss_step=2.05e+3]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:09<00:15,  1.96it/s, v_num=4, train_loss_step=2.05e+3]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:09<00:15,  1.96it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:10<00:15,  1.95it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:10<00:15,  1.95it/s, v_num=4, train_loss_step=1.47e+3]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:10<00:14,  1.94it/s, v_num=4, train_loss_step=1.47e+3]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:10<00:14,  1.94it/s, v_num=4, train_loss_step=3.93e+3]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:11<00:14,  1.93it/s, v_num=4, train_loss_step=3.93e+3]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:11<00:14,  1.93it/s, v_num=4, train_loss_step=2.98e+3]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:11<00:13,  1.93it/s, v_num=4, train_loss_step=2.98e+3]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:11<00:13,  1.93it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:12<00:13,  1.93it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:12<00:13,  1.93it/s, v_num=4, train_loss_step=2.13e+3]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:12<00:12,  1.94it/s, v_num=4, train_loss_step=2.13e+3]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:12<00:12,  1.94it/s, v_num=4, train_loss_step=2.38e+3]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:13<00:12,  1.94it/s, v_num=4, train_loss_step=2.38e+3]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:13<00:12,  1.93it/s, v_num=4, train_loss_step=6.14e+3]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:13<00:11,  1.93it/s, v_num=4, train_loss_step=6.14e+3]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:13<00:11,  1.93it/s, v_num=4, train_loss_step=3.34e+3]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:14<00:11,  1.93it/s, v_num=4, train_loss_step=3.34e+3]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:14<00:11,  1.93it/s, v_num=4, train_loss_step=3.99e+3]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:14<00:10,  1.94it/s, v_num=4, train_loss_step=3.99e+3]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:14<00:10,  1.94it/s, v_num=4, train_loss_step=2.37e+3]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:15<00:10,  1.94it/s, v_num=4, train_loss_step=2.37e+3]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:15<00:10,  1.94it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:15<00:09,  1.95it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:15<00:09,  1.95it/s, v_num=4, train_loss_step=3.28e+3]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:16<00:09,  1.95it/s, v_num=4, train_loss_step=3.28e+3]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:16<00:09,  1.95it/s, v_num=4, train_loss_step=4.03e+3]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:16<00:08,  1.95it/s, v_num=4, train_loss_step=4.03e+3]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:16<00:08,  1.95it/s, v_num=4, train_loss_step=3.5e+3] Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:17<00:08,  1.95it/s, v_num=4, train_loss_step=3.5e+3]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:17<00:08,  1.95it/s, v_num=4, train_loss_step=2.74e+3]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:17<00:07,  1.96it/s, v_num=4, train_loss_step=2.74e+3]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:17<00:07,  1.96it/s, v_num=4, train_loss_step=4.05e+3]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:18<00:07,  1.96it/s, v_num=4, train_loss_step=4.05e+3]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:18<00:07,  1.96it/s, v_num=4, train_loss_step=2.6e+3] Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:18<00:06,  1.96it/s, v_num=4, train_loss_step=2.6e+3]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:18<00:06,  1.96it/s, v_num=4, train_loss_step=2.17e+3]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:19<00:06,  1.96it/s, v_num=4, train_loss_step=2.17e+3]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:19<00:06,  1.96it/s, v_num=4, train_loss_step=2.33e+3]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:19<00:05,  1.96it/s, v_num=4, train_loss_step=2.33e+3]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:19<00:05,  1.96it/s, v_num=4, train_loss_step=3.51e+3]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:20<00:05,  1.96it/s, v_num=4, train_loss_step=3.51e+3]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:20<00:05,  1.96it/s, v_num=4, train_loss_step=4.37e+3]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:20<00:04,  1.97it/s, v_num=4, train_loss_step=4.37e+3]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:20<00:04,  1.97it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:21<00:04,  1.97it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:21<00:04,  1.97it/s, v_num=4, train_loss_step=1.97e+3]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:21<00:03,  1.98it/s, v_num=4, train_loss_step=1.97e+3]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:21<00:03,  1.98it/s, v_num=4, train_loss_step=1.9e+3] Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:22<00:03,  1.98it/s, v_num=4, train_loss_step=1.9e+3]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:22<00:03,  1.98it/s, v_num=4, train_loss_step=2.64e+3]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:22<00:02,  1.98it/s, v_num=4, train_loss_step=2.64e+3]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:22<00:02,  1.98it/s, v_num=4, train_loss_step=1.64e+3]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:23<00:02,  1.99it/s, v_num=4, train_loss_step=1.64e+3]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:23<00:02,  1.99it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:23<00:01,  1.99it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:23<00:01,  1.99it/s, v_num=4, train_loss_step=3.73e+3]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:24<00:01,  2.00it/s, v_num=4, train_loss_step=3.73e+3]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:24<00:01,  2.00it/s, v_num=4, train_loss_step=1.55e+3]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=1.55e+3]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=2.41e+3]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=2.41e+3]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=1.77e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.04it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.88it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.88it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]         Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   2%|â–         | 1/50 [00:00<00:23,  2.06it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   2%|â–         | 1/50 [00:00<00:24,  2.02it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   4%|â–         | 2/50 [00:01<00:24,  1.98it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   4%|â–         | 2/50 [00:01<00:24,  1.93it/s, v_num=4, train_loss_step=2.25e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   6%|â–Œ         | 3/50 [00:01<00:23,  1.99it/s, v_num=4, train_loss_step=2.25e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   6%|â–Œ         | 3/50 [00:01<00:23,  1.98it/s, v_num=4, train_loss_step=4.9e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:   8%|â–Š         | 4/50 [00:01<00:22,  2.00it/s, v_num=4, train_loss_step=4.9e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   8%|â–Š         | 4/50 [00:01<00:22,  2.00it/s, v_num=4, train_loss_step=2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]  Epoch 1:  10%|â–ˆ         | 5/50 [00:02<00:22,  2.02it/s, v_num=4, train_loss_step=2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  10%|â–ˆ         | 5/50 [00:02<00:22,  2.02it/s, v_num=4, train_loss_step=2.92e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  12%|â–ˆâ–        | 6/50 [00:02<00:21,  2.04it/s, v_num=4, train_loss_step=2.92e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  12%|â–ˆâ–        | 6/50 [00:02<00:21,  2.04it/s, v_num=4, train_loss_step=1.32e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.06it/s, v_num=4, train_loss_step=1.32e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.06it/s, v_num=4, train_loss_step=1.71e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:20,  2.04it/s, v_num=4, train_loss_step=1.71e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:20,  2.04it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  18%|â–ˆâ–Š        | 9/50 [00:04<00:20,  2.02it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  18%|â–ˆâ–Š        | 9/50 [00:04<00:20,  2.02it/s, v_num=4, train_loss_step=2.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  20%|â–ˆâ–ˆ        | 10/50 [00:05<00:20,  1.99it/s, v_num=4, train_loss_step=2.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  20%|â–ˆâ–ˆ        | 10/50 [00:05<00:20,  1.98it/s, v_num=4, train_loss_step=3.09e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:19,  1.98it/s, v_num=4, train_loss_step=3.09e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:19,  1.96it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  24%|â–ˆâ–ˆâ–       | 12/50 [00:06<00:19,  1.97it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  24%|â–ˆâ–ˆâ–       | 12/50 [00:06<00:19,  1.96it/s, v_num=4, train_loss_step=2.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:18,  1.96it/s, v_num=4, train_loss_step=2.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:18,  1.95it/s, v_num=4, train_loss_step=2.21e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:07<00:18,  1.95it/s, v_num=4, train_loss_step=2.21e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:07<00:18,  1.93it/s, v_num=4, train_loss_step=3.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:18,  1.93it/s, v_num=4, train_loss_step=3.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:18,  1.92it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:08<00:17,  1.93it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:08<00:17,  1.92it/s, v_num=4, train_loss_step=2.28e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:17,  1.93it/s, v_num=4, train_loss_step=2.28e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:17,  1.92it/s, v_num=4, train_loss_step=3.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:09<00:16,  1.93it/s, v_num=4, train_loss_step=3.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:09<00:16,  1.92it/s, v_num=4, train_loss_step=4.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:09<00:16,  1.93it/s, v_num=4, train_loss_step=4.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:09<00:16,  1.93it/s, v_num=4, train_loss_step=1.78e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:10<00:15,  1.94it/s, v_num=4, train_loss_step=1.78e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:10<00:15,  1.94it/s, v_num=4, train_loss_step=1.7e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:10<00:14,  1.95it/s, v_num=4, train_loss_step=1.7e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:10<00:14,  1.95it/s, v_num=4, train_loss_step=3.2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:11<00:14,  1.96it/s, v_num=4, train_loss_step=3.2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:11<00:14,  1.96it/s, v_num=4, train_loss_step=1.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:11<00:13,  1.97it/s, v_num=4, train_loss_step=1.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:11<00:13,  1.97it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:12<00:13,  1.97it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:12<00:13,  1.97it/s, v_num=4, train_loss_step=3.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:12<00:12,  1.98it/s, v_num=4, train_loss_step=3.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:12<00:12,  1.97it/s, v_num=4, train_loss_step=2.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:13<00:12,  1.98it/s, v_num=4, train_loss_step=2.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:13<00:12,  1.98it/s, v_num=4, train_loss_step=2.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:13<00:11,  1.98it/s, v_num=4, train_loss_step=2.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:13<00:11,  1.98it/s, v_num=4, train_loss_step=1.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:14<00:11,  1.98it/s, v_num=4, train_loss_step=1.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:14<00:11,  1.98it/s, v_num=4, train_loss_step=2.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:14<00:10,  1.98it/s, v_num=4, train_loss_step=2.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:14<00:10,  1.98it/s, v_num=4, train_loss_step=1.88e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:15<00:10,  1.99it/s, v_num=4, train_loss_step=1.88e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:15<00:10,  1.99it/s, v_num=4, train_loss_step=4.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:15<00:09,  1.99it/s, v_num=4, train_loss_step=4.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:15<00:09,  1.99it/s, v_num=4, train_loss_step=1.81e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:16<00:09,  1.99it/s, v_num=4, train_loss_step=1.81e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:16<00:09,  1.99it/s, v_num=4, train_loss_step=2.87e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:16<00:08,  2.00it/s, v_num=4, train_loss_step=2.87e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:16<00:08,  2.00it/s, v_num=4, train_loss_step=3.55e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:16<00:07,  2.00it/s, v_num=4, train_loss_step=3.55e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:16<00:07,  2.00it/s, v_num=4, train_loss_step=3.11e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:17<00:07,  2.01it/s, v_num=4, train_loss_step=3.11e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:17<00:07,  2.01it/s, v_num=4, train_loss_step=2.15e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:17<00:06,  2.01it/s, v_num=4, train_loss_step=2.15e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:17<00:06,  2.01it/s, v_num=4, train_loss_step=2.46e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:18<00:06,  2.01it/s, v_num=4, train_loss_step=2.46e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:18<00:06,  2.01it/s, v_num=4, train_loss_step=4.67e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:18<00:05,  2.02it/s, v_num=4, train_loss_step=4.67e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:18<00:05,  2.02it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:19<00:05,  2.02it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:19<00:05,  2.02it/s, v_num=4, train_loss_step=3.02e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:19<00:04,  2.03it/s, v_num=4, train_loss_step=3.02e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:19<00:04,  2.03it/s, v_num=4, train_loss_step=2.86e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:20<00:04,  2.03it/s, v_num=4, train_loss_step=2.86e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:20<00:04,  2.03it/s, v_num=4, train_loss_step=2.68e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:20<00:03,  2.03it/s, v_num=4, train_loss_step=2.68e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:20<00:03,  2.03it/s, v_num=4, train_loss_step=2.62e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:21<00:03,  2.04it/s, v_num=4, train_loss_step=2.62e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:21<00:03,  2.04it/s, v_num=4, train_loss_step=1.76e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:21<00:02,  2.04it/s, v_num=4, train_loss_step=1.76e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:21<00:02,  2.04it/s, v_num=4, train_loss_step=2.34e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:22<00:02,  2.04it/s, v_num=4, train_loss_step=2.34e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:22<00:02,  2.04it/s, v_num=4, train_loss_step=1.84e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=1.84e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=2.56e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=2.56e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=2.36e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=2.36e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:24<00:00,  2.06it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:24<00:00,  2.06it/s, v_num=4, train_loss_step=1.89e+3, val_loss=440.0, train_loss_epoch=2.8e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s][A
                                                                      [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.94it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.8e+3]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.94it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]         Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   2%|â–         | 1/50 [00:00<00:22,  2.16it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   2%|â–         | 1/50 [00:00<00:23,  2.08it/s, v_num=4, train_loss_step=3.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   4%|â–         | 2/50 [00:00<00:22,  2.11it/s, v_num=4, train_loss_step=3.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   4%|â–         | 2/50 [00:00<00:22,  2.10it/s, v_num=4, train_loss_step=2.42e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   6%|â–Œ         | 3/50 [00:01<00:22,  2.11it/s, v_num=4, train_loss_step=2.42e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   6%|â–Œ         | 3/50 [00:01<00:22,  2.10it/s, v_num=4, train_loss_step=1.98e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   8%|â–Š         | 4/50 [00:01<00:21,  2.11it/s, v_num=4, train_loss_step=1.98e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   8%|â–Š         | 4/50 [00:01<00:21,  2.10it/s, v_num=4, train_loss_step=4.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  10%|â–ˆ         | 5/50 [00:02<00:21,  2.12it/s, v_num=4, train_loss_step=4.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  10%|â–ˆ         | 5/50 [00:02<00:21,  2.11it/s, v_num=4, train_loss_step=1.94e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  12%|â–ˆâ–        | 6/50 [00:02<00:20,  2.11it/s, v_num=4, train_loss_step=1.94e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  12%|â–ˆâ–        | 6/50 [00:02<00:20,  2.11it/s, v_num=4, train_loss_step=1.45e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.11it/s, v_num=4, train_loss_step=1.45e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.11it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:19,  2.12it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:19,  2.12it/s, v_num=4, train_loss_step=3.53e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  18%|â–ˆâ–Š        | 9/50 [00:04<00:19,  2.14it/s, v_num=4, train_loss_step=3.53e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  18%|â–ˆâ–Š        | 9/50 [00:04<00:19,  2.14it/s, v_num=4, train_loss_step=2.9e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:18,  2.15it/s, v_num=4, train_loss_step=2.9e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:18,  2.15it/s, v_num=4, train_loss_step=4.36e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:18,  2.15it/s, v_num=4, train_loss_step=4.36e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:18,  2.15it/s, v_num=4, train_loss_step=3.05e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:17,  2.16it/s, v_num=4, train_loss_step=3.05e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:17,  2.16it/s, v_num=4, train_loss_step=2.31e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:17,  2.16it/s, v_num=4, train_loss_step=2.31e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:17,  2.16it/s, v_num=4, train_loss_step=2.21e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:16,  2.16it/s, v_num=4, train_loss_step=2.21e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:16,  2.16it/s, v_num=4, train_loss_step=3.27e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:06<00:16,  2.15it/s, v_num=4, train_loss_step=3.27e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:06<00:16,  2.15it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:07<00:15,  2.16it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:07<00:15,  2.16it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:07<00:15,  2.15it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:07<00:15,  2.15it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=3.01e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=3.01e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=1.6e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:09<00:13,  2.15it/s, v_num=4, train_loss_step=1.6e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:09<00:13,  2.15it/s, v_num=4, train_loss_step=2.24e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:09<00:13,  2.16it/s, v_num=4, train_loss_step=2.24e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:09<00:13,  2.16it/s, v_num=4, train_loss_step=2.22e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:10<00:12,  2.16it/s, v_num=4, train_loss_step=2.22e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:10<00:12,  2.16it/s, v_num=4, train_loss_step=2.17e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:10<00:12,  2.15it/s, v_num=4, train_loss_step=2.17e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:10<00:12,  2.15it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:11<00:12,  2.15it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:11<00:12,  2.15it/s, v_num=4, train_loss_step=1.51e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:11<00:11,  2.15it/s, v_num=4, train_loss_step=1.51e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:11<00:11,  2.15it/s, v_num=4, train_loss_step=1.4e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:12<00:11,  2.14it/s, v_num=4, train_loss_step=1.4e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:12<00:11,  2.14it/s, v_num=4, train_loss_step=1.5e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:12<00:10,  2.14it/s, v_num=4, train_loss_step=1.5e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:12<00:10,  2.14it/s, v_num=4, train_loss_step=3.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:13<00:10,  2.15it/s, v_num=4, train_loss_step=3.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:13<00:10,  2.15it/s, v_num=4, train_loss_step=3.77e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=3.77e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=2.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=2.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:14<00:08,  2.15it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:14<00:08,  2.15it/s, v_num=4, train_loss_step=1.97e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:14<00:08,  2.16it/s, v_num=4, train_loss_step=1.97e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:14<00:08,  2.16it/s, v_num=4, train_loss_step=2.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=2.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=2.96e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:16<00:06,  2.15it/s, v_num=4, train_loss_step=2.96e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:16<00:06,  2.15it/s, v_num=4, train_loss_step=3.61e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:16<00:06,  2.15it/s, v_num=4, train_loss_step=3.61e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:16<00:06,  2.14it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:17<00:06,  2.15it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:17<00:06,  2.14it/s, v_num=4, train_loss_step=2.46e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:17<00:05,  2.14it/s, v_num=4, train_loss_step=2.46e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:17<00:05,  2.14it/s, v_num=4, train_loss_step=3.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:18<00:05,  2.14it/s, v_num=4, train_loss_step=3.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:18<00:05,  2.14it/s, v_num=4, train_loss_step=2.32e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:18<00:04,  2.14it/s, v_num=4, train_loss_step=2.32e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:18<00:04,  2.14it/s, v_num=4, train_loss_step=1.79e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:19<00:04,  2.14it/s, v_num=4, train_loss_step=1.79e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:19<00:04,  2.14it/s, v_num=4, train_loss_step=2.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:19<00:03,  2.14it/s, v_num=4, train_loss_step=2.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:19<00:03,  2.14it/s, v_num=4, train_loss_step=1.73e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:20<00:03,  2.14it/s, v_num=4, train_loss_step=1.73e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:20<00:03,  2.14it/s, v_num=4, train_loss_step=3.35e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:20<00:02,  2.14it/s, v_num=4, train_loss_step=3.35e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:20<00:02,  2.14it/s, v_num=4, train_loss_step=2.33e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:21<00:02,  2.14it/s, v_num=4, train_loss_step=2.33e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:21<00:02,  2.14it/s, v_num=4, train_loss_step=4.58e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=4.58e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=2.3e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=2.3e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=1.63e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=1.63e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=2.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.14it/s, v_num=4, train_loss_step=2.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.14it/s, v_num=4, train_loss_step=2.91e+3, val_loss=464.0, train_loss_epoch=2.64e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s][A
                                                                      [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:24<00:00,  2.03it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.64e+3]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:24<00:00,  2.03it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]         Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   2%|â–         | 1/50 [00:00<00:22,  2.15it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   2%|â–         | 1/50 [00:00<00:22,  2.14it/s, v_num=4, train_loss_step=3.16e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   4%|â–         | 2/50 [00:00<00:22,  2.12it/s, v_num=4, train_loss_step=3.16e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   4%|â–         | 2/50 [00:00<00:22,  2.12it/s, v_num=4, train_loss_step=2.62e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   6%|â–Œ         | 3/50 [00:01<00:22,  2.12it/s, v_num=4, train_loss_step=2.62e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   6%|â–Œ         | 3/50 [00:01<00:22,  2.12it/s, v_num=4, train_loss_step=1.78e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   8%|â–Š         | 4/50 [00:01<00:21,  2.14it/s, v_num=4, train_loss_step=1.78e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   8%|â–Š         | 4/50 [00:01<00:21,  2.13it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]   Epoch 3:  10%|â–ˆ         | 5/50 [00:02<00:20,  2.15it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  10%|â–ˆ         | 5/50 [00:02<00:20,  2.15it/s, v_num=4, train_loss_step=2.54e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  12%|â–ˆâ–        | 6/50 [00:02<00:20,  2.16it/s, v_num=4, train_loss_step=2.54e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  12%|â–ˆâ–        | 6/50 [00:02<00:20,  2.16it/s, v_num=4, train_loss_step=1.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.15it/s, v_num=4, train_loss_step=1.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.15it/s, v_num=4, train_loss_step=1.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:19,  2.14it/s, v_num=4, train_loss_step=1.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:19,  2.13it/s, v_num=4, train_loss_step=2.25e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  18%|â–ˆâ–Š        | 9/50 [00:04<00:19,  2.13it/s, v_num=4, train_loss_step=2.25e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  18%|â–ˆâ–Š        | 9/50 [00:04<00:19,  2.12it/s, v_num=4, train_loss_step=1.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:18,  2.13it/s, v_num=4, train_loss_step=1.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:18,  2.13it/s, v_num=4, train_loss_step=1.81e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:18,  2.13it/s, v_num=4, train_loss_step=1.81e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:18,  2.13it/s, v_num=4, train_loss_step=1.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:17,  2.13it/s, v_num=4, train_loss_step=1.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:17,  2.13it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:17,  2.14it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:17,  2.14it/s, v_num=4, train_loss_step=2.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:16,  2.14it/s, v_num=4, train_loss_step=2.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:16,  2.13it/s, v_num=4, train_loss_step=3.67e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=3.67e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=1.93e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=1.93e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=3.86e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=3.86e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:08<00:14,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:08<00:14,  2.12it/s, v_num=4, train_loss_step=1.96e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:09<00:14,  2.12it/s, v_num=4, train_loss_step=1.96e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:09<00:14,  2.12it/s, v_num=4, train_loss_step=2.2e+3, val_loss=485.0, train_loss_epoch=2.49e+3] Epoch 3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:09<00:13,  2.12it/s, v_num=4, train_loss_step=2.2e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:09<00:13,  2.12it/s, v_num=4, train_loss_step=2.55e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:10<00:13,  2.12it/s, v_num=4, train_loss_step=2.55e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:10<00:13,  2.12it/s, v_num=4, train_loss_step=2.42e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:10<00:12,  2.12it/s, v_num=4, train_loss_step=2.42e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:10<00:12,  2.12it/s, v_num=4, train_loss_step=2.98e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:11<00:12,  2.12it/s, v_num=4, train_loss_step=2.98e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:11<00:12,  2.12it/s, v_num=4, train_loss_step=3.21e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:11<00:11,  2.12it/s, v_num=4, train_loss_step=3.21e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:11<00:11,  2.12it/s, v_num=4, train_loss_step=2.66e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:12<00:11,  2.12it/s, v_num=4, train_loss_step=2.66e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:12<00:11,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:12<00:10,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:12<00:10,  2.12it/s, v_num=4, train_loss_step=2.64e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:13<00:10,  2.12it/s, v_num=4, train_loss_step=2.64e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:13<00:10,  2.12it/s, v_num=4, train_loss_step=2.17e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:13<00:09,  2.12it/s, v_num=4, train_loss_step=2.17e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:13<00:09,  2.12it/s, v_num=4, train_loss_step=2e+3, val_loss=485.0, train_loss_epoch=2.49e+3]   Epoch 3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:14<00:09,  2.13it/s, v_num=4, train_loss_step=2e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:14<00:09,  2.12it/s, v_num=4, train_loss_step=2.71e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:14<00:08,  2.12it/s, v_num=4, train_loss_step=2.71e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:14<00:08,  2.12it/s, v_num=4, train_loss_step=1.82e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=1.82e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]   Epoch 3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=2.76e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=2.76e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=1.41e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=1.41e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=2.9e+3, val_loss=485.0, train_loss_epoch=2.49e+3] Epoch 3:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=2.9e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=2.63e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:17<00:05,  2.12it/s, v_num=4, train_loss_step=2.63e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:17<00:05,  2.12it/s, v_num=4, train_loss_step=1.97e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:18<00:05,  2.12it/s, v_num=4, train_loss_step=1.97e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:18<00:05,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:18<00:04,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:18<00:04,  2.12it/s, v_num=4, train_loss_step=2.49e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:19<00:04,  2.12it/s, v_num=4, train_loss_step=2.49e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:19<00:04,  2.12it/s, v_num=4, train_loss_step=2.47e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:19<00:03,  2.10it/s, v_num=4, train_loss_step=2.47e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:20<00:03,  2.10it/s, v_num=4, train_loss_step=3.51e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:20<00:03,  2.10it/s, v_num=4, train_loss_step=3.51e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:20<00:03,  2.10it/s, v_num=4, train_loss_step=2.83e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:20<00:02,  2.10it/s, v_num=4, train_loss_step=2.83e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:20<00:02,  2.10it/s, v_num=4, train_loss_step=3.28e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:21<00:02,  2.10it/s, v_num=4, train_loss_step=3.28e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:21<00:02,  2.10it/s, v_num=4, train_loss_step=3.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:21<00:01,  2.10it/s, v_num=4, train_loss_step=3.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:21<00:01,  2.10it/s, v_num=4, train_loss_step=2.36e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:22<00:01,  2.10it/s, v_num=4, train_loss_step=2.36e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:22<00:01,  2.10it/s, v_num=4, train_loss_step=2.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:22<00:00,  2.11it/s, v_num=4, train_loss_step=2.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:22<00:00,  2.11it/s, v_num=4, train_loss_step=1.99e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=1.99e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=3.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=3.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=3.35e+3, val_loss=485.0, train_loss_epoch=2.49e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s][A
                                                                      [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.99it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.49e+3]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.99it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]         Epoch 4:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   2%|â–         | 1/50 [00:00<00:22,  2.16it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   2%|â–         | 1/50 [00:00<00:23,  2.08it/s, v_num=4, train_loss_step=2.21e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   4%|â–         | 2/50 [00:00<00:23,  2.06it/s, v_num=4, train_loss_step=2.21e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   4%|â–         | 2/50 [00:00<00:23,  2.01it/s, v_num=4, train_loss_step=2.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   6%|â–Œ         | 3/50 [00:01<00:22,  2.06it/s, v_num=4, train_loss_step=2.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   6%|â–Œ         | 3/50 [00:01<00:23,  2.03it/s, v_num=4, train_loss_step=1.7e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:   8%|â–Š         | 4/50 [00:01<00:22,  2.05it/s, v_num=4, train_loss_step=1.7e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   8%|â–Š         | 4/50 [00:01<00:22,  2.05it/s, v_num=4, train_loss_step=1.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  10%|â–ˆ         | 5/50 [00:02<00:22,  2.04it/s, v_num=4, train_loss_step=1.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  10%|â–ˆ         | 5/50 [00:02<00:22,  2.04it/s, v_num=4, train_loss_step=1.55e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  12%|â–ˆâ–        | 6/50 [00:02<00:21,  2.04it/s, v_num=4, train_loss_step=1.55e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  12%|â–ˆâ–        | 6/50 [00:02<00:21,  2.03it/s, v_num=4, train_loss_step=2.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  14%|â–ˆâ–        | 7/50 [00:03<00:20,  2.05it/s, v_num=4, train_loss_step=2.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  14%|â–ˆâ–        | 7/50 [00:03<00:21,  2.04it/s, v_num=4, train_loss_step=2.22e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:20,  2.05it/s, v_num=4, train_loss_step=2.22e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  16%|â–ˆâ–Œ        | 8/50 [00:03<00:20,  2.05it/s, v_num=4, train_loss_step=2.02e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  18%|â–ˆâ–Š        | 9/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=2.02e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  18%|â–ˆâ–Š        | 9/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=1.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=1.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  20%|â–ˆâ–ˆ        | 10/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=3.03e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:18,  2.09it/s, v_num=4, train_loss_step=3.03e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  22%|â–ˆâ–ˆâ–       | 11/50 [00:05<00:18,  2.09it/s, v_num=4, train_loss_step=2.39e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:18,  2.10it/s, v_num=4, train_loss_step=2.39e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  24%|â–ˆâ–ˆâ–       | 12/50 [00:05<00:18,  2.10it/s, v_num=4, train_loss_step=2.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:17,  2.11it/s, v_num=4, train_loss_step=2.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:06<00:17,  2.11it/s, v_num=4, train_loss_step=1.64e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:17,  2.10it/s, v_num=4, train_loss_step=1.64e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:06<00:17,  2.10it/s, v_num=4, train_loss_step=2.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:16,  2.10it/s, v_num=4, train_loss_step=2.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:07<00:16,  2.10it/s, v_num=4, train_loss_step=2.78e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:07<00:16,  2.10it/s, v_num=4, train_loss_step=2.78e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:07<00:16,  2.09it/s, v_num=4, train_loss_step=3.43e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:15,  2.10it/s, v_num=4, train_loss_step=3.43e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:08<00:15,  2.09it/s, v_num=4, train_loss_step=3.4e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:08<00:15,  2.10it/s, v_num=4, train_loss_step=3.4e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:08<00:15,  2.09it/s, v_num=4, train_loss_step=2.11e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.11e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.38e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=2.38e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=3.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=3.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=2.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.48e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.48e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.68e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:11<00:11,  2.09it/s, v_num=4, train_loss_step=2.68e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:11<00:11,  2.09it/s, v_num=4, train_loss_step=1.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:12<00:11,  2.10it/s, v_num=4, train_loss_step=1.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:12<00:11,  2.10it/s, v_num=4, train_loss_step=1.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:12<00:10,  2.10it/s, v_num=4, train_loss_step=1.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:12<00:10,  2.10it/s, v_num=4, train_loss_step=2.14e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:13<00:10,  2.10it/s, v_num=4, train_loss_step=2.14e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:13<00:10,  2.10it/s, v_num=4, train_loss_step=1.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:13<00:10,  2.10it/s, v_num=4, train_loss_step=1.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:13<00:10,  2.09it/s, v_num=4, train_loss_step=1.57e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:14<00:09,  2.09it/s, v_num=4, train_loss_step=1.57e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:14<00:09,  2.09it/s, v_num=4, train_loss_step=1.52e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:14<00:09,  2.09it/s, v_num=4, train_loss_step=1.52e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:14<00:09,  2.08it/s, v_num=4, train_loss_step=2.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:15<00:08,  2.08it/s, v_num=4, train_loss_step=2.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:15<00:08,  2.07it/s, v_num=4, train_loss_step=2.9e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:15<00:08,  2.08it/s, v_num=4, train_loss_step=2.9e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:15<00:08,  2.07it/s, v_num=4, train_loss_step=2.82e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=2.82e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=3.27e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=3.27e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=2.13e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=2.13e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=3.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=3.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=1.93e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=1.93e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=3.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:19<00:04,  2.07it/s, v_num=4, train_loss_step=3.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:19<00:04,  2.07it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:19<00:04,  2.08it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:19<00:04,  2.08it/s, v_num=4, train_loss_step=4.72e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=4.72e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=2.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=2.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=1.96e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=1.96e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=2.1e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=2.1e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=2.44e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=2.44e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=3.53e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=3.53e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=2.09e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:22<00:00,  2.09it/s, v_num=4, train_loss_step=2.09e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:22<00:00,  2.09it/s, v_num=4, train_loss_step=2.84e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:23<00:00,  2.09it/s, v_num=4, train_loss_step=2.84e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:23<00:00,  2.09it/s, v_num=4, train_loss_step=1.83e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.10it/s, v_num=4, train_loss_step=1.83e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.10it/s, v_num=4, train_loss_step=2.73e+3, val_loss=499.0, train_loss_epoch=2.57e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.41it/s][A
                                                                      [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.97it/s, v_num=4, train_loss_step=2.73e+3, val_loss=516.0, train_loss_epoch=2.57e+3]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.97it/s, v_num=4, train_loss_step=2.73e+3, val_loss=516.0, train_loss_epoch=2.44e+3]`Trainer.fit` stopped: `max_epochs=5` reached.
Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.96it/s, v_num=4, train_loss_step=2.73e+3, val_loss=516.0, train_loss_epoch=2.44e+3] * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node2.py', reloading

 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node2.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node1.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node1.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node1.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node2.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node4.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node4.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node6.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node7.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/run.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/bin/python3: can't open file '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node8.py': [Errno 2] No such file or directory
