/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Serving Flask app 'node8'
 * Debug mode: on
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://localhost:8008
[33mPress CTRL+C to quit[0m
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
127.0.0.1 - - [28/Jul/2025 14:27:04] "GET /train/ HTTP/1.1" 200 -
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]Finding best initial lr:   1%|          | 1/100 [00:01<02:00,  1.22s/it]Finding best initial lr:   2%|▏         | 2/100 [00:01<01:16,  1.28it/s]Finding best initial lr:   3%|▎         | 3/100 [00:02<01:01,  1.57it/s]Finding best initial lr:   4%|▍         | 4/100 [00:02<00:55,  1.74it/s]Finding best initial lr:   5%|▌         | 5/100 [00:03<00:50,  1.88it/s]Finding best initial lr:   6%|▌         | 6/100 [00:03<00:48,  1.93it/s]Finding best initial lr:   7%|▋         | 7/100 [00:04<00:48,  1.93it/s]Finding best initial lr:   8%|▊         | 8/100 [00:04<00:48,  1.91it/s]Finding best initial lr:   9%|▉         | 9/100 [00:05<00:46,  1.95it/s]Finding best initial lr:  10%|█         | 10/100 [00:05<00:46,  1.95it/s]Finding best initial lr:  11%|█         | 11/100 [00:06<00:44,  1.99it/s]Finding best initial lr:  12%|█▏        | 12/100 [00:06<00:43,  2.04it/s]Finding best initial lr:  13%|█▎        | 13/100 [00:07<00:42,  2.07it/s]Finding best initial lr:  14%|█▍        | 14/100 [00:07<00:42,  2.02it/s]Finding best initial lr:  15%|█▌        | 15/100 [00:08<00:45,  1.86it/s]Finding best initial lr:  16%|█▌        | 16/100 [00:08<00:43,  1.92it/s]Finding best initial lr:  17%|█▋        | 17/100 [00:09<00:41,  1.99it/s]Finding best initial lr:  18%|█▊        | 18/100 [00:09<00:40,  2.02it/s]Finding best initial lr:  19%|█▉        | 19/100 [00:10<00:39,  2.03it/s]Finding best initial lr:  20%|██        | 20/100 [00:10<00:39,  2.02it/s]Finding best initial lr:  21%|██        | 21/100 [00:11<00:38,  2.04it/s]Finding best initial lr:  22%|██▏       | 22/100 [00:11<00:38,  2.02it/s]Finding best initial lr:  23%|██▎       | 23/100 [00:12<00:38,  1.99it/s]Finding best initial lr:  24%|██▍       | 24/100 [00:12<00:38,  2.00it/s]Finding best initial lr:  25%|██▌       | 25/100 [00:13<00:38,  1.95it/s]Finding best initial lr:  26%|██▌       | 26/100 [00:13<00:37,  1.95it/s]Finding best initial lr:  27%|██▋       | 27/100 [00:14<00:36,  1.99it/s]Finding best initial lr:  28%|██▊       | 28/100 [00:14<00:36,  1.96it/s]Finding best initial lr:  29%|██▉       | 29/100 [00:15<00:36,  1.95it/s]Finding best initial lr:  30%|███       | 30/100 [00:15<00:36,  1.92it/s]Finding best initial lr:  31%|███       | 31/100 [00:16<00:35,  1.96it/s]Finding best initial lr:  32%|███▏      | 32/100 [00:16<00:33,  2.01it/s]Finding best initial lr:  33%|███▎      | 33/100 [00:17<00:32,  2.05it/s]Finding best initial lr:  34%|███▍      | 34/100 [00:17<00:31,  2.10it/s]Finding best initial lr:  35%|███▌      | 35/100 [00:18<00:30,  2.10it/s]Finding best initial lr:  36%|███▌      | 36/100 [00:18<00:30,  2.12it/s]Finding best initial lr:  37%|███▋      | 37/100 [00:19<00:29,  2.12it/s]Finding best initial lr:  38%|███▊      | 38/100 [00:19<00:29,  2.10it/s]Finding best initial lr:  39%|███▉      | 39/100 [00:19<00:29,  2.07it/s]Finding best initial lr:  40%|████      | 40/100 [00:20<00:29,  2.07it/s]Finding best initial lr:  41%|████      | 41/100 [00:20<00:28,  2.04it/s]Finding best initial lr:  42%|████▏     | 42/100 [00:21<00:27,  2.07it/s]Finding best initial lr:  43%|████▎     | 43/100 [00:21<00:26,  2.11it/s]Finding best initial lr:  44%|████▍     | 44/100 [00:22<00:26,  2.13it/s]Finding best initial lr:  45%|████▌     | 45/100 [00:22<00:25,  2.15it/s]Finding best initial lr:  46%|████▌     | 46/100 [00:23<00:24,  2.16it/s]Finding best initial lr:  47%|████▋     | 47/100 [00:23<00:24,  2.12it/s]Finding best initial lr:  48%|████▊     | 48/100 [00:24<00:25,  2.08it/s]Finding best initial lr:  49%|████▉     | 49/100 [00:24<00:24,  2.10it/s]Finding best initial lr:  50%|█████     | 50/100 [00:25<00:23,  2.10it/s]Finding best initial lr:  51%|█████     | 51/100 [00:26<00:34,  1.42it/s]Finding best initial lr:  52%|█████▏    | 52/100 [00:26<00:30,  1.56it/s]Finding best initial lr:  53%|█████▎    | 53/100 [00:27<00:28,  1.68it/s]Finding best initial lr:  54%|█████▍    | 54/100 [00:27<00:25,  1.77it/s]Finding best initial lr:  55%|█████▌    | 55/100 [00:28<00:24,  1.83it/s]Finding best initial lr:  56%|█████▌    | 56/100 [00:28<00:22,  1.92it/s]Finding best initial lr:  57%|█████▋    | 57/100 [00:29<00:21,  2.00it/s]Finding best initial lr:  58%|█████▊    | 58/100 [00:29<00:20,  2.06it/s]Finding best initial lr:  59%|█████▉    | 59/100 [00:30<00:19,  2.08it/s]Finding best initial lr:  60%|██████    | 60/100 [00:30<00:19,  2.06it/s]Finding best initial lr:  61%|██████    | 61/100 [00:31<00:18,  2.08it/s]Finding best initial lr:  62%|██████▏   | 62/100 [00:31<00:18,  2.06it/s]Finding best initial lr:  63%|██████▎   | 63/100 [00:32<00:17,  2.07it/s]Finding best initial lr:  64%|██████▍   | 64/100 [00:32<00:17,  2.09it/s]Finding best initial lr:  65%|██████▌   | 65/100 [00:33<00:16,  2.14it/s]Finding best initial lr:  66%|██████▌   | 66/100 [00:33<00:15,  2.14it/s]Finding best initial lr:  67%|██████▋   | 67/100 [00:34<00:15,  2.17it/s]Finding best initial lr:  68%|██████▊   | 68/100 [00:34<00:14,  2.19it/s]Finding best initial lr:  69%|██████▉   | 69/100 [00:34<00:14,  2.14it/s]Finding best initial lr:  70%|███████   | 70/100 [00:35<00:14,  2.13it/s]Finding best initial lr:  71%|███████   | 71/100 [00:35<00:14,  2.07it/s]Finding best initial lr:  72%|███████▏  | 72/100 [00:36<00:13,  2.08it/s]Finding best initial lr:  73%|███████▎  | 73/100 [00:36<00:13,  2.04it/s]Finding best initial lr:  74%|███████▍  | 74/100 [00:37<00:12,  2.08it/s]Finding best initial lr:  75%|███████▌  | 75/100 [00:37<00:11,  2.12it/s]Finding best initial lr:  76%|███████▌  | 76/100 [00:38<00:11,  2.16it/s]Finding best initial lr:  77%|███████▋  | 77/100 [00:38<00:10,  2.17it/s]Finding best initial lr:  78%|███████▊  | 78/100 [00:39<00:10,  2.14it/s]Finding best initial lr:  79%|███████▉  | 79/100 [00:39<00:09,  2.11it/s]Finding best initial lr:  80%|████████  | 80/100 [00:40<00:09,  2.09it/s]Finding best initial lr:  81%|████████  | 81/100 [00:40<00:09,  2.06it/s]Finding best initial lr:  82%|████████▏ | 82/100 [00:41<00:08,  2.05it/s]Finding best initial lr:  83%|████████▎ | 83/100 [00:41<00:08,  2.07it/s]Finding best initial lr:  84%|████████▍ | 84/100 [00:42<00:07,  2.06it/s]Finding best initial lr:  85%|████████▌ | 85/100 [00:42<00:07,  2.10it/s]Finding best initial lr:  86%|████████▌ | 86/100 [00:43<00:06,  2.11it/s]Finding best initial lr:  87%|████████▋ | 87/100 [00:43<00:06,  2.15it/s]Finding best initial lr:  87%|████████▋ | 87/100 [00:43<00:06,  2.00it/s]
LR finder stopped early after 87 steps due to diverging loss.
Learning rate set to 2.137962089502232e-05
Restoring states from the checkpoint path at /home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/.lr_find_03cc6786-cf62-4bcd-94d8-e7c9000fee17.ckpt
Restored all states from the checkpoint at /home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/.lr_find_03cc6786-cf62-4bcd-94d8-e7c9000fee17.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name                               | Type                            | Params | Mode 
------------------------------------------------------------------------------------------------
0  | loss                               | MultiLoss                       | 0      | train
1  | logging_metrics                    | ModuleList                      | 0      | train
2  | input_embeddings                   | MultiEmbedding                  | 570    | train
3  | prescalers                         | ModuleDict                      | 240    | train
4  | static_variable_selection          | VariableSelectionNetwork        | 6.7 K  | train
5  | encoder_variable_selection         | VariableSelectionNetwork        | 3.7 K  | train
6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.6 K  | train
7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train
8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train
9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train
10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train
11 | lstm_encoder                       | LSTM                            | 2.2 K  | train
12 | lstm_decoder                       | LSTM                            | 2.2 K  | train
13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train
14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train
15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train
16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K  | train
17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train
18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train
19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train
20 | output_layer                       | ModuleList                      | 51     | train
------------------------------------------------------------------------------------------------
26.7 K    Trainable params
0         Non-trainable params
26.7 K    Total params
0.107     Total estimated model params size (MB)
443       Modules in train mode
0         Modules in eval mode
Sanity Checking: |          | 0/? [00:00<?, ?it/s]/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]                                                                           /home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/50 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s] Epoch 0:   2%|▏         | 1/50 [00:00<00:25,  1.96it/s]Epoch 0:   2%|▏         | 1/50 [00:00<00:25,  1.96it/s, v_num=4, train_loss_step=1.91e+3]Epoch 0:   4%|▍         | 2/50 [00:01<00:24,  1.98it/s, v_num=4, train_loss_step=1.91e+3]Epoch 0:   4%|▍         | 2/50 [00:01<00:24,  1.98it/s, v_num=4, train_loss_step=3.72e+3]Epoch 0:   6%|▌         | 3/50 [00:01<00:23,  2.00it/s, v_num=4, train_loss_step=3.72e+3]Epoch 0:   6%|▌         | 3/50 [00:01<00:23,  1.99it/s, v_num=4, train_loss_step=4e+3]   Epoch 0:   8%|▊         | 4/50 [00:01<00:22,  2.02it/s, v_num=4, train_loss_step=4e+3]Epoch 0:   8%|▊         | 4/50 [00:01<00:22,  2.02it/s, v_num=4, train_loss_step=3.06e+3]Epoch 0:  10%|█         | 5/50 [00:02<00:22,  2.03it/s, v_num=4, train_loss_step=3.06e+3]Epoch 0:  10%|█         | 5/50 [00:02<00:22,  2.03it/s, v_num=4, train_loss_step=3.07e+3]Epoch 0:  12%|█▏        | 6/50 [00:02<00:21,  2.03it/s, v_num=4, train_loss_step=3.07e+3]Epoch 0:  12%|█▏        | 6/50 [00:02<00:21,  2.03it/s, v_num=4, train_loss_step=2.51e+3]Epoch 0:  14%|█▍        | 7/50 [00:03<00:21,  2.00it/s, v_num=4, train_loss_step=2.51e+3]Epoch 0:  14%|█▍        | 7/50 [00:03<00:21,  2.00it/s, v_num=4, train_loss_step=2.81e+3]Epoch 0:  16%|█▌        | 8/50 [00:03<00:20,  2.01it/s, v_num=4, train_loss_step=2.81e+3]Epoch 0:  16%|█▌        | 8/50 [00:04<00:21,  1.99it/s, v_num=4, train_loss_step=2.88e+3]Epoch 0:  18%|█▊        | 9/50 [00:04<00:20,  2.00it/s, v_num=4, train_loss_step=2.88e+3]Epoch 0:  18%|█▊        | 9/50 [00:04<00:20,  2.00it/s, v_num=4, train_loss_step=2.45e+3]Epoch 0:  20%|██        | 10/50 [00:04<00:19,  2.01it/s, v_num=4, train_loss_step=2.45e+3]Epoch 0:  20%|██        | 10/50 [00:04<00:19,  2.01it/s, v_num=4, train_loss_step=3.36e+3]Epoch 0:  22%|██▏       | 11/50 [00:05<00:19,  2.02it/s, v_num=4, train_loss_step=3.36e+3]Epoch 0:  22%|██▏       | 11/50 [00:05<00:19,  2.02it/s, v_num=4, train_loss_step=2.82e+3]Epoch 0:  24%|██▍       | 12/50 [00:05<00:18,  2.03it/s, v_num=4, train_loss_step=2.82e+3]Epoch 0:  24%|██▍       | 12/50 [00:05<00:18,  2.03it/s, v_num=4, train_loss_step=2.46e+3]Epoch 0:  26%|██▌       | 13/50 [00:06<00:18,  2.03it/s, v_num=4, train_loss_step=2.46e+3]Epoch 0:  26%|██▌       | 13/50 [00:06<00:18,  2.03it/s, v_num=4, train_loss_step=2.36e+3]Epoch 0:  28%|██▊       | 14/50 [00:06<00:17,  2.02it/s, v_num=4, train_loss_step=2.36e+3]Epoch 0:  28%|██▊       | 14/50 [00:06<00:17,  2.02it/s, v_num=4, train_loss_step=3.64e+3]Epoch 0:  30%|███       | 15/50 [00:07<00:17,  1.99it/s, v_num=4, train_loss_step=3.64e+3]Epoch 0:  30%|███       | 15/50 [00:07<00:17,  1.99it/s, v_num=4, train_loss_step=3.27e+3]Epoch 0:  32%|███▏      | 16/50 [00:08<00:17,  1.99it/s, v_num=4, train_loss_step=3.27e+3]Epoch 0:  32%|███▏      | 16/50 [00:08<00:17,  1.98it/s, v_num=4, train_loss_step=2.32e+3]Epoch 0:  34%|███▍      | 17/50 [00:08<00:16,  1.97it/s, v_num=4, train_loss_step=2.32e+3]Epoch 0:  34%|███▍      | 17/50 [00:08<00:16,  1.96it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  36%|███▌      | 18/50 [00:09<00:16,  1.96it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  36%|███▌      | 18/50 [00:09<00:16,  1.96it/s, v_num=4, train_loss_step=2.05e+3]Epoch 0:  38%|███▊      | 19/50 [00:09<00:15,  1.96it/s, v_num=4, train_loss_step=2.05e+3]Epoch 0:  38%|███▊      | 19/50 [00:09<00:15,  1.96it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  40%|████      | 20/50 [00:10<00:15,  1.95it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  40%|████      | 20/50 [00:10<00:15,  1.95it/s, v_num=4, train_loss_step=1.47e+3]Epoch 0:  42%|████▏     | 21/50 [00:10<00:14,  1.94it/s, v_num=4, train_loss_step=1.47e+3]Epoch 0:  42%|████▏     | 21/50 [00:10<00:14,  1.94it/s, v_num=4, train_loss_step=3.93e+3]Epoch 0:  44%|████▍     | 22/50 [00:11<00:14,  1.93it/s, v_num=4, train_loss_step=3.93e+3]Epoch 0:  44%|████▍     | 22/50 [00:11<00:14,  1.93it/s, v_num=4, train_loss_step=2.98e+3]Epoch 0:  46%|████▌     | 23/50 [00:11<00:13,  1.93it/s, v_num=4, train_loss_step=2.98e+3]Epoch 0:  46%|████▌     | 23/50 [00:11<00:13,  1.93it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  48%|████▊     | 24/50 [00:12<00:13,  1.93it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  48%|████▊     | 24/50 [00:12<00:13,  1.93it/s, v_num=4, train_loss_step=2.13e+3]Epoch 0:  50%|█████     | 25/50 [00:12<00:12,  1.94it/s, v_num=4, train_loss_step=2.13e+3]Epoch 0:  50%|█████     | 25/50 [00:12<00:12,  1.94it/s, v_num=4, train_loss_step=2.38e+3]Epoch 0:  52%|█████▏    | 26/50 [00:13<00:12,  1.94it/s, v_num=4, train_loss_step=2.38e+3]Epoch 0:  52%|█████▏    | 26/50 [00:13<00:12,  1.93it/s, v_num=4, train_loss_step=6.14e+3]Epoch 0:  54%|█████▍    | 27/50 [00:13<00:11,  1.93it/s, v_num=4, train_loss_step=6.14e+3]Epoch 0:  54%|█████▍    | 27/50 [00:13<00:11,  1.93it/s, v_num=4, train_loss_step=3.34e+3]Epoch 0:  56%|█████▌    | 28/50 [00:14<00:11,  1.93it/s, v_num=4, train_loss_step=3.34e+3]Epoch 0:  56%|█████▌    | 28/50 [00:14<00:11,  1.93it/s, v_num=4, train_loss_step=3.99e+3]Epoch 0:  58%|█████▊    | 29/50 [00:14<00:10,  1.94it/s, v_num=4, train_loss_step=3.99e+3]Epoch 0:  58%|█████▊    | 29/50 [00:14<00:10,  1.94it/s, v_num=4, train_loss_step=2.37e+3]Epoch 0:  60%|██████    | 30/50 [00:15<00:10,  1.94it/s, v_num=4, train_loss_step=2.37e+3]Epoch 0:  60%|██████    | 30/50 [00:15<00:10,  1.94it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  62%|██████▏   | 31/50 [00:15<00:09,  1.95it/s, v_num=4, train_loss_step=2.18e+3]Epoch 0:  62%|██████▏   | 31/50 [00:15<00:09,  1.95it/s, v_num=4, train_loss_step=3.28e+3]Epoch 0:  64%|██████▍   | 32/50 [00:16<00:09,  1.95it/s, v_num=4, train_loss_step=3.28e+3]Epoch 0:  64%|██████▍   | 32/50 [00:16<00:09,  1.95it/s, v_num=4, train_loss_step=4.03e+3]Epoch 0:  66%|██████▌   | 33/50 [00:16<00:08,  1.95it/s, v_num=4, train_loss_step=4.03e+3]Epoch 0:  66%|██████▌   | 33/50 [00:16<00:08,  1.95it/s, v_num=4, train_loss_step=3.5e+3] Epoch 0:  68%|██████▊   | 34/50 [00:17<00:08,  1.95it/s, v_num=4, train_loss_step=3.5e+3]Epoch 0:  68%|██████▊   | 34/50 [00:17<00:08,  1.95it/s, v_num=4, train_loss_step=2.74e+3]Epoch 0:  70%|███████   | 35/50 [00:17<00:07,  1.96it/s, v_num=4, train_loss_step=2.74e+3]Epoch 0:  70%|███████   | 35/50 [00:17<00:07,  1.96it/s, v_num=4, train_loss_step=4.05e+3]Epoch 0:  72%|███████▏  | 36/50 [00:18<00:07,  1.96it/s, v_num=4, train_loss_step=4.05e+3]Epoch 0:  72%|███████▏  | 36/50 [00:18<00:07,  1.96it/s, v_num=4, train_loss_step=2.6e+3] Epoch 0:  74%|███████▍  | 37/50 [00:18<00:06,  1.96it/s, v_num=4, train_loss_step=2.6e+3]Epoch 0:  74%|███████▍  | 37/50 [00:18<00:06,  1.96it/s, v_num=4, train_loss_step=2.17e+3]Epoch 0:  76%|███████▌  | 38/50 [00:19<00:06,  1.96it/s, v_num=4, train_loss_step=2.17e+3]Epoch 0:  76%|███████▌  | 38/50 [00:19<00:06,  1.96it/s, v_num=4, train_loss_step=2.33e+3]Epoch 0:  78%|███████▊  | 39/50 [00:19<00:05,  1.96it/s, v_num=4, train_loss_step=2.33e+3]Epoch 0:  78%|███████▊  | 39/50 [00:19<00:05,  1.96it/s, v_num=4, train_loss_step=3.51e+3]Epoch 0:  80%|████████  | 40/50 [00:20<00:05,  1.96it/s, v_num=4, train_loss_step=3.51e+3]Epoch 0:  80%|████████  | 40/50 [00:20<00:05,  1.96it/s, v_num=4, train_loss_step=4.37e+3]Epoch 0:  82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s, v_num=4, train_loss_step=4.37e+3]Epoch 0:  82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  84%|████████▍ | 42/50 [00:21<00:04,  1.97it/s, v_num=4, train_loss_step=2.21e+3]Epoch 0:  84%|████████▍ | 42/50 [00:21<00:04,  1.97it/s, v_num=4, train_loss_step=1.97e+3]Epoch 0:  86%|████████▌ | 43/50 [00:21<00:03,  1.98it/s, v_num=4, train_loss_step=1.97e+3]Epoch 0:  86%|████████▌ | 43/50 [00:21<00:03,  1.98it/s, v_num=4, train_loss_step=1.9e+3] Epoch 0:  88%|████████▊ | 44/50 [00:22<00:03,  1.98it/s, v_num=4, train_loss_step=1.9e+3]Epoch 0:  88%|████████▊ | 44/50 [00:22<00:03,  1.98it/s, v_num=4, train_loss_step=2.64e+3]Epoch 0:  90%|█████████ | 45/50 [00:22<00:02,  1.98it/s, v_num=4, train_loss_step=2.64e+3]Epoch 0:  90%|█████████ | 45/50 [00:22<00:02,  1.98it/s, v_num=4, train_loss_step=1.64e+3]Epoch 0:  92%|█████████▏| 46/50 [00:23<00:02,  1.99it/s, v_num=4, train_loss_step=1.64e+3]Epoch 0:  92%|█████████▏| 46/50 [00:23<00:02,  1.99it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  94%|█████████▍| 47/50 [00:23<00:01,  1.99it/s, v_num=4, train_loss_step=1.93e+3]Epoch 0:  94%|█████████▍| 47/50 [00:23<00:01,  1.99it/s, v_num=4, train_loss_step=3.73e+3]Epoch 0:  96%|█████████▌| 48/50 [00:24<00:01,  2.00it/s, v_num=4, train_loss_step=3.73e+3]Epoch 0:  96%|█████████▌| 48/50 [00:24<00:01,  2.00it/s, v_num=4, train_loss_step=1.55e+3]Epoch 0:  98%|█████████▊| 49/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=1.55e+3]Epoch 0:  98%|█████████▊| 49/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=2.41e+3]Epoch 0: 100%|██████████| 50/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=2.41e+3]Epoch 0: 100%|██████████| 50/50 [00:24<00:00,  2.00it/s, v_num=4, train_loss_step=1.77e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s][A
                                                                      [AEpoch 0: 100%|██████████| 50/50 [00:26<00:00,  1.88it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0]Epoch 0: 100%|██████████| 50/50 [00:26<00:00,  1.88it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]         Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   2%|▏         | 1/50 [00:00<00:23,  2.06it/s, v_num=4, train_loss_step=1.77e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   2%|▏         | 1/50 [00:00<00:24,  2.02it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   4%|▍         | 2/50 [00:01<00:24,  1.98it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   4%|▍         | 2/50 [00:01<00:24,  1.93it/s, v_num=4, train_loss_step=2.25e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   6%|▌         | 3/50 [00:01<00:23,  1.99it/s, v_num=4, train_loss_step=2.25e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   6%|▌         | 3/50 [00:01<00:23,  1.98it/s, v_num=4, train_loss_step=4.9e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:   8%|▊         | 4/50 [00:01<00:22,  2.00it/s, v_num=4, train_loss_step=4.9e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:   8%|▊         | 4/50 [00:01<00:22,  2.00it/s, v_num=4, train_loss_step=2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]  Epoch 1:  10%|█         | 5/50 [00:02<00:22,  2.02it/s, v_num=4, train_loss_step=2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  10%|█         | 5/50 [00:02<00:22,  2.02it/s, v_num=4, train_loss_step=2.92e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  12%|█▏        | 6/50 [00:02<00:21,  2.04it/s, v_num=4, train_loss_step=2.92e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  12%|█▏        | 6/50 [00:02<00:21,  2.04it/s, v_num=4, train_loss_step=1.32e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  14%|█▍        | 7/50 [00:03<00:20,  2.06it/s, v_num=4, train_loss_step=1.32e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  14%|█▍        | 7/50 [00:03<00:20,  2.06it/s, v_num=4, train_loss_step=1.71e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  16%|█▌        | 8/50 [00:03<00:20,  2.04it/s, v_num=4, train_loss_step=1.71e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  16%|█▌        | 8/50 [00:03<00:20,  2.04it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  18%|█▊        | 9/50 [00:04<00:20,  2.02it/s, v_num=4, train_loss_step=2.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  18%|█▊        | 9/50 [00:04<00:20,  2.02it/s, v_num=4, train_loss_step=2.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  20%|██        | 10/50 [00:05<00:20,  1.99it/s, v_num=4, train_loss_step=2.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  20%|██        | 10/50 [00:05<00:20,  1.98it/s, v_num=4, train_loss_step=3.09e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  22%|██▏       | 11/50 [00:05<00:19,  1.98it/s, v_num=4, train_loss_step=3.09e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  22%|██▏       | 11/50 [00:05<00:19,  1.96it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  24%|██▍       | 12/50 [00:06<00:19,  1.97it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  24%|██▍       | 12/50 [00:06<00:19,  1.96it/s, v_num=4, train_loss_step=2.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  26%|██▌       | 13/50 [00:06<00:18,  1.96it/s, v_num=4, train_loss_step=2.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  26%|██▌       | 13/50 [00:06<00:18,  1.95it/s, v_num=4, train_loss_step=2.21e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  28%|██▊       | 14/50 [00:07<00:18,  1.95it/s, v_num=4, train_loss_step=2.21e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  28%|██▊       | 14/50 [00:07<00:18,  1.93it/s, v_num=4, train_loss_step=3.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  30%|███       | 15/50 [00:07<00:18,  1.93it/s, v_num=4, train_loss_step=3.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  30%|███       | 15/50 [00:07<00:18,  1.92it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  32%|███▏      | 16/50 [00:08<00:17,  1.93it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  32%|███▏      | 16/50 [00:08<00:17,  1.92it/s, v_num=4, train_loss_step=2.28e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  34%|███▍      | 17/50 [00:08<00:17,  1.93it/s, v_num=4, train_loss_step=2.28e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  34%|███▍      | 17/50 [00:08<00:17,  1.92it/s, v_num=4, train_loss_step=3.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  36%|███▌      | 18/50 [00:09<00:16,  1.93it/s, v_num=4, train_loss_step=3.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  36%|███▌      | 18/50 [00:09<00:16,  1.92it/s, v_num=4, train_loss_step=4.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  38%|███▊      | 19/50 [00:09<00:16,  1.93it/s, v_num=4, train_loss_step=4.23e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  38%|███▊      | 19/50 [00:09<00:16,  1.93it/s, v_num=4, train_loss_step=1.78e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  40%|████      | 20/50 [00:10<00:15,  1.94it/s, v_num=4, train_loss_step=1.78e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  40%|████      | 20/50 [00:10<00:15,  1.94it/s, v_num=4, train_loss_step=1.7e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:  42%|████▏     | 21/50 [00:10<00:14,  1.95it/s, v_num=4, train_loss_step=1.7e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  42%|████▏     | 21/50 [00:10<00:14,  1.95it/s, v_num=4, train_loss_step=3.2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  44%|████▍     | 22/50 [00:11<00:14,  1.96it/s, v_num=4, train_loss_step=3.2e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  44%|████▍     | 22/50 [00:11<00:14,  1.96it/s, v_num=4, train_loss_step=1.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  46%|████▌     | 23/50 [00:11<00:13,  1.97it/s, v_num=4, train_loss_step=1.74e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  46%|████▌     | 23/50 [00:11<00:13,  1.97it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  48%|████▊     | 24/50 [00:12<00:13,  1.97it/s, v_num=4, train_loss_step=2.04e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  48%|████▊     | 24/50 [00:12<00:13,  1.97it/s, v_num=4, train_loss_step=3.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  50%|█████     | 25/50 [00:12<00:12,  1.98it/s, v_num=4, train_loss_step=3.83e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  50%|█████     | 25/50 [00:12<00:12,  1.97it/s, v_num=4, train_loss_step=2.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:  52%|█████▏    | 26/50 [00:13<00:12,  1.98it/s, v_num=4, train_loss_step=2.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  52%|█████▏    | 26/50 [00:13<00:12,  1.98it/s, v_num=4, train_loss_step=2.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  54%|█████▍    | 27/50 [00:13<00:11,  1.98it/s, v_num=4, train_loss_step=2.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  54%|█████▍    | 27/50 [00:13<00:11,  1.98it/s, v_num=4, train_loss_step=1.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  56%|█████▌    | 28/50 [00:14<00:11,  1.98it/s, v_num=4, train_loss_step=1.95e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  56%|█████▌    | 28/50 [00:14<00:11,  1.98it/s, v_num=4, train_loss_step=2.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  58%|█████▊    | 29/50 [00:14<00:10,  1.98it/s, v_num=4, train_loss_step=2.91e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  58%|█████▊    | 29/50 [00:14<00:10,  1.98it/s, v_num=4, train_loss_step=1.88e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  60%|██████    | 30/50 [00:15<00:10,  1.99it/s, v_num=4, train_loss_step=1.88e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  60%|██████    | 30/50 [00:15<00:10,  1.99it/s, v_num=4, train_loss_step=4.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3] Epoch 1:  62%|██████▏   | 31/50 [00:15<00:09,  1.99it/s, v_num=4, train_loss_step=4.1e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  62%|██████▏   | 31/50 [00:15<00:09,  1.99it/s, v_num=4, train_loss_step=1.81e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  64%|██████▍   | 32/50 [00:16<00:09,  1.99it/s, v_num=4, train_loss_step=1.81e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  64%|██████▍   | 32/50 [00:16<00:09,  1.99it/s, v_num=4, train_loss_step=2.87e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  66%|██████▌   | 33/50 [00:16<00:08,  2.00it/s, v_num=4, train_loss_step=2.87e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  66%|██████▌   | 33/50 [00:16<00:08,  2.00it/s, v_num=4, train_loss_step=3.55e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  68%|██████▊   | 34/50 [00:16<00:07,  2.00it/s, v_num=4, train_loss_step=3.55e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  68%|██████▊   | 34/50 [00:16<00:07,  2.00it/s, v_num=4, train_loss_step=3.11e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  70%|███████   | 35/50 [00:17<00:07,  2.01it/s, v_num=4, train_loss_step=3.11e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  70%|███████   | 35/50 [00:17<00:07,  2.01it/s, v_num=4, train_loss_step=2.15e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  72%|███████▏  | 36/50 [00:17<00:06,  2.01it/s, v_num=4, train_loss_step=2.15e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  72%|███████▏  | 36/50 [00:17<00:06,  2.01it/s, v_num=4, train_loss_step=2.46e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  74%|███████▍  | 37/50 [00:18<00:06,  2.01it/s, v_num=4, train_loss_step=2.46e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  74%|███████▍  | 37/50 [00:18<00:06,  2.01it/s, v_num=4, train_loss_step=4.67e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  76%|███████▌  | 38/50 [00:18<00:05,  2.02it/s, v_num=4, train_loss_step=4.67e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  76%|███████▌  | 38/50 [00:18<00:05,  2.02it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  78%|███████▊  | 39/50 [00:19<00:05,  2.02it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  78%|███████▊  | 39/50 [00:19<00:05,  2.02it/s, v_num=4, train_loss_step=3.02e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  80%|████████  | 40/50 [00:19<00:04,  2.03it/s, v_num=4, train_loss_step=3.02e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  80%|████████  | 40/50 [00:19<00:04,  2.03it/s, v_num=4, train_loss_step=2.86e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  82%|████████▏ | 41/50 [00:20<00:04,  2.03it/s, v_num=4, train_loss_step=2.86e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  82%|████████▏ | 41/50 [00:20<00:04,  2.03it/s, v_num=4, train_loss_step=2.68e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  84%|████████▍ | 42/50 [00:20<00:03,  2.03it/s, v_num=4, train_loss_step=2.68e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  84%|████████▍ | 42/50 [00:20<00:03,  2.03it/s, v_num=4, train_loss_step=2.62e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  86%|████████▌ | 43/50 [00:21<00:03,  2.04it/s, v_num=4, train_loss_step=2.62e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  86%|████████▌ | 43/50 [00:21<00:03,  2.04it/s, v_num=4, train_loss_step=1.76e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  88%|████████▊ | 44/50 [00:21<00:02,  2.04it/s, v_num=4, train_loss_step=1.76e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  88%|████████▊ | 44/50 [00:21<00:02,  2.04it/s, v_num=4, train_loss_step=2.34e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  90%|█████████ | 45/50 [00:22<00:02,  2.04it/s, v_num=4, train_loss_step=2.34e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  90%|█████████ | 45/50 [00:22<00:02,  2.04it/s, v_num=4, train_loss_step=1.84e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  92%|█████████▏| 46/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=1.84e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  92%|█████████▏| 46/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  94%|█████████▍| 47/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=3.19e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  94%|█████████▍| 47/50 [00:22<00:01,  2.05it/s, v_num=4, train_loss_step=2.56e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  96%|█████████▌| 48/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=2.56e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  96%|█████████▌| 48/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=2.36e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  98%|█████████▊| 49/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=2.36e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1:  98%|█████████▊| 49/50 [00:23<00:00,  2.05it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1: 100%|██████████| 50/50 [00:24<00:00,  2.06it/s, v_num=4, train_loss_step=1.75e+3, val_loss=440.0, train_loss_epoch=2.8e+3]Epoch 1: 100%|██████████| 50/50 [00:24<00:00,  2.06it/s, v_num=4, train_loss_step=1.89e+3, val_loss=440.0, train_loss_epoch=2.8e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s][A
                                                                      [AEpoch 1: 100%|██████████| 50/50 [00:25<00:00,  1.94it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.8e+3]Epoch 1: 100%|██████████| 50/50 [00:25<00:00,  1.94it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]         Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   2%|▏         | 1/50 [00:00<00:22,  2.16it/s, v_num=4, train_loss_step=1.89e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   2%|▏         | 1/50 [00:00<00:23,  2.08it/s, v_num=4, train_loss_step=3.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   4%|▍         | 2/50 [00:00<00:22,  2.11it/s, v_num=4, train_loss_step=3.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   4%|▍         | 2/50 [00:00<00:22,  2.10it/s, v_num=4, train_loss_step=2.42e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   6%|▌         | 3/50 [00:01<00:22,  2.11it/s, v_num=4, train_loss_step=2.42e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   6%|▌         | 3/50 [00:01<00:22,  2.10it/s, v_num=4, train_loss_step=1.98e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   8%|▊         | 4/50 [00:01<00:21,  2.11it/s, v_num=4, train_loss_step=1.98e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:   8%|▊         | 4/50 [00:01<00:21,  2.10it/s, v_num=4, train_loss_step=4.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  10%|█         | 5/50 [00:02<00:21,  2.12it/s, v_num=4, train_loss_step=4.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  10%|█         | 5/50 [00:02<00:21,  2.11it/s, v_num=4, train_loss_step=1.94e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  12%|█▏        | 6/50 [00:02<00:20,  2.11it/s, v_num=4, train_loss_step=1.94e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  12%|█▏        | 6/50 [00:02<00:20,  2.11it/s, v_num=4, train_loss_step=1.45e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  14%|█▍        | 7/50 [00:03<00:20,  2.11it/s, v_num=4, train_loss_step=1.45e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  14%|█▍        | 7/50 [00:03<00:20,  2.11it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  16%|█▌        | 8/50 [00:03<00:19,  2.12it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  16%|█▌        | 8/50 [00:03<00:19,  2.12it/s, v_num=4, train_loss_step=3.53e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  18%|█▊        | 9/50 [00:04<00:19,  2.14it/s, v_num=4, train_loss_step=3.53e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  18%|█▊        | 9/50 [00:04<00:19,  2.14it/s, v_num=4, train_loss_step=2.9e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  20%|██        | 10/50 [00:04<00:18,  2.15it/s, v_num=4, train_loss_step=2.9e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  20%|██        | 10/50 [00:04<00:18,  2.15it/s, v_num=4, train_loss_step=4.36e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  22%|██▏       | 11/50 [00:05<00:18,  2.15it/s, v_num=4, train_loss_step=4.36e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  22%|██▏       | 11/50 [00:05<00:18,  2.15it/s, v_num=4, train_loss_step=3.05e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  24%|██▍       | 12/50 [00:05<00:17,  2.16it/s, v_num=4, train_loss_step=3.05e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  24%|██▍       | 12/50 [00:05<00:17,  2.16it/s, v_num=4, train_loss_step=2.31e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  26%|██▌       | 13/50 [00:06<00:17,  2.16it/s, v_num=4, train_loss_step=2.31e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  26%|██▌       | 13/50 [00:06<00:17,  2.16it/s, v_num=4, train_loss_step=2.21e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  28%|██▊       | 14/50 [00:06<00:16,  2.16it/s, v_num=4, train_loss_step=2.21e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  28%|██▊       | 14/50 [00:06<00:16,  2.16it/s, v_num=4, train_loss_step=3.27e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  30%|███       | 15/50 [00:06<00:16,  2.15it/s, v_num=4, train_loss_step=3.27e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  30%|███       | 15/50 [00:06<00:16,  2.15it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  32%|███▏      | 16/50 [00:07<00:15,  2.16it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  32%|███▏      | 16/50 [00:07<00:15,  2.16it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  34%|███▍      | 17/50 [00:07<00:15,  2.15it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  34%|███▍      | 17/50 [00:07<00:15,  2.15it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  36%|███▌      | 18/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  36%|███▌      | 18/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=3.01e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  38%|███▊      | 19/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=3.01e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  38%|███▊      | 19/50 [00:08<00:14,  2.15it/s, v_num=4, train_loss_step=1.6e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  40%|████      | 20/50 [00:09<00:13,  2.15it/s, v_num=4, train_loss_step=1.6e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  40%|████      | 20/50 [00:09<00:13,  2.15it/s, v_num=4, train_loss_step=2.24e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  42%|████▏     | 21/50 [00:09<00:13,  2.16it/s, v_num=4, train_loss_step=2.24e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  42%|████▏     | 21/50 [00:09<00:13,  2.16it/s, v_num=4, train_loss_step=2.22e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  44%|████▍     | 22/50 [00:10<00:12,  2.16it/s, v_num=4, train_loss_step=2.22e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  44%|████▍     | 22/50 [00:10<00:12,  2.16it/s, v_num=4, train_loss_step=2.17e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  46%|████▌     | 23/50 [00:10<00:12,  2.15it/s, v_num=4, train_loss_step=2.17e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  46%|████▌     | 23/50 [00:10<00:12,  2.15it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  48%|████▊     | 24/50 [00:11<00:12,  2.15it/s, v_num=4, train_loss_step=2.16e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  48%|████▊     | 24/50 [00:11<00:12,  2.15it/s, v_num=4, train_loss_step=1.51e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  50%|█████     | 25/50 [00:11<00:11,  2.15it/s, v_num=4, train_loss_step=1.51e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  50%|█████     | 25/50 [00:11<00:11,  2.15it/s, v_num=4, train_loss_step=1.4e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  52%|█████▏    | 26/50 [00:12<00:11,  2.14it/s, v_num=4, train_loss_step=1.4e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  52%|█████▏    | 26/50 [00:12<00:11,  2.14it/s, v_num=4, train_loss_step=1.5e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  54%|█████▍    | 27/50 [00:12<00:10,  2.14it/s, v_num=4, train_loss_step=1.5e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  54%|█████▍    | 27/50 [00:12<00:10,  2.14it/s, v_num=4, train_loss_step=3.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  56%|█████▌    | 28/50 [00:13<00:10,  2.15it/s, v_num=4, train_loss_step=3.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  56%|█████▌    | 28/50 [00:13<00:10,  2.15it/s, v_num=4, train_loss_step=3.77e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  58%|█████▊    | 29/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=3.77e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  58%|█████▊    | 29/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=2.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  60%|██████    | 30/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=2.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  60%|██████    | 30/50 [00:13<00:09,  2.15it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  62%|██████▏   | 31/50 [00:14<00:08,  2.15it/s, v_num=4, train_loss_step=1.65e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  62%|██████▏   | 31/50 [00:14<00:08,  2.15it/s, v_num=4, train_loss_step=1.97e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  64%|██████▍   | 32/50 [00:14<00:08,  2.16it/s, v_num=4, train_loss_step=1.97e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  64%|██████▍   | 32/50 [00:14<00:08,  2.16it/s, v_num=4, train_loss_step=2.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  66%|██████▌   | 33/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=2.28e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  66%|██████▌   | 33/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  68%|██████▊   | 34/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  68%|██████▊   | 34/50 [00:15<00:07,  2.15it/s, v_num=4, train_loss_step=2.96e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  70%|███████   | 35/50 [00:16<00:06,  2.15it/s, v_num=4, train_loss_step=2.96e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  70%|███████   | 35/50 [00:16<00:06,  2.15it/s, v_num=4, train_loss_step=3.61e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  72%|███████▏  | 36/50 [00:16<00:06,  2.15it/s, v_num=4, train_loss_step=3.61e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  72%|███████▏  | 36/50 [00:16<00:06,  2.14it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  74%|███████▍  | 37/50 [00:17<00:06,  2.15it/s, v_num=4, train_loss_step=1.74e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  74%|███████▍  | 37/50 [00:17<00:06,  2.14it/s, v_num=4, train_loss_step=2.46e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  76%|███████▌  | 38/50 [00:17<00:05,  2.14it/s, v_num=4, train_loss_step=2.46e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  76%|███████▌  | 38/50 [00:17<00:05,  2.14it/s, v_num=4, train_loss_step=3.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  78%|███████▊  | 39/50 [00:18<00:05,  2.14it/s, v_num=4, train_loss_step=3.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  78%|███████▊  | 39/50 [00:18<00:05,  2.14it/s, v_num=4, train_loss_step=2.32e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  80%|████████  | 40/50 [00:18<00:04,  2.14it/s, v_num=4, train_loss_step=2.32e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  80%|████████  | 40/50 [00:18<00:04,  2.14it/s, v_num=4, train_loss_step=1.79e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  82%|████████▏ | 41/50 [00:19<00:04,  2.14it/s, v_num=4, train_loss_step=1.79e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  82%|████████▏ | 41/50 [00:19<00:04,  2.14it/s, v_num=4, train_loss_step=2.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  84%|████████▍ | 42/50 [00:19<00:03,  2.14it/s, v_num=4, train_loss_step=2.26e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  84%|████████▍ | 42/50 [00:19<00:03,  2.14it/s, v_num=4, train_loss_step=1.73e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  86%|████████▌ | 43/50 [00:20<00:03,  2.14it/s, v_num=4, train_loss_step=1.73e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  86%|████████▌ | 43/50 [00:20<00:03,  2.14it/s, v_num=4, train_loss_step=3.35e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  88%|████████▊ | 44/50 [00:20<00:02,  2.14it/s, v_num=4, train_loss_step=3.35e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  88%|████████▊ | 44/50 [00:20<00:02,  2.14it/s, v_num=4, train_loss_step=2.33e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  90%|█████████ | 45/50 [00:21<00:02,  2.14it/s, v_num=4, train_loss_step=2.33e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  90%|█████████ | 45/50 [00:21<00:02,  2.14it/s, v_num=4, train_loss_step=4.58e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  92%|█████████▏| 46/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=4.58e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  92%|█████████▏| 46/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=2.3e+3, val_loss=464.0, train_loss_epoch=2.64e+3] Epoch 2:  94%|█████████▍| 47/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=2.3e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  94%|█████████▍| 47/50 [00:21<00:01,  2.14it/s, v_num=4, train_loss_step=1.63e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  96%|█████████▌| 48/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=1.63e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  96%|█████████▌| 48/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  98%|█████████▊| 49/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=2.02e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2:  98%|█████████▊| 49/50 [00:22<00:00,  2.14it/s, v_num=4, train_loss_step=2.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2: 100%|██████████| 50/50 [00:23<00:00,  2.14it/s, v_num=4, train_loss_step=2.88e+3, val_loss=464.0, train_loss_epoch=2.64e+3]Epoch 2: 100%|██████████| 50/50 [00:23<00:00,  2.14it/s, v_num=4, train_loss_step=2.91e+3, val_loss=464.0, train_loss_epoch=2.64e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s][A
                                                                      [AEpoch 2: 100%|██████████| 50/50 [00:24<00:00,  2.03it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.64e+3]Epoch 2: 100%|██████████| 50/50 [00:24<00:00,  2.03it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]         Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   2%|▏         | 1/50 [00:00<00:22,  2.15it/s, v_num=4, train_loss_step=2.91e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   2%|▏         | 1/50 [00:00<00:22,  2.14it/s, v_num=4, train_loss_step=3.16e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   4%|▍         | 2/50 [00:00<00:22,  2.12it/s, v_num=4, train_loss_step=3.16e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   4%|▍         | 2/50 [00:00<00:22,  2.12it/s, v_num=4, train_loss_step=2.62e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   6%|▌         | 3/50 [00:01<00:22,  2.12it/s, v_num=4, train_loss_step=2.62e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   6%|▌         | 3/50 [00:01<00:22,  2.12it/s, v_num=4, train_loss_step=1.78e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   8%|▊         | 4/50 [00:01<00:21,  2.14it/s, v_num=4, train_loss_step=1.78e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:   8%|▊         | 4/50 [00:01<00:21,  2.13it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]   Epoch 3:  10%|█         | 5/50 [00:02<00:20,  2.15it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  10%|█         | 5/50 [00:02<00:20,  2.15it/s, v_num=4, train_loss_step=2.54e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  12%|█▏        | 6/50 [00:02<00:20,  2.16it/s, v_num=4, train_loss_step=2.54e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  12%|█▏        | 6/50 [00:02<00:20,  2.16it/s, v_num=4, train_loss_step=1.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  14%|█▍        | 7/50 [00:03<00:20,  2.15it/s, v_num=4, train_loss_step=1.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  14%|█▍        | 7/50 [00:03<00:20,  2.15it/s, v_num=4, train_loss_step=1.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  16%|█▌        | 8/50 [00:03<00:19,  2.14it/s, v_num=4, train_loss_step=1.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  16%|█▌        | 8/50 [00:03<00:19,  2.13it/s, v_num=4, train_loss_step=2.25e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  18%|█▊        | 9/50 [00:04<00:19,  2.13it/s, v_num=4, train_loss_step=2.25e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  18%|█▊        | 9/50 [00:04<00:19,  2.12it/s, v_num=4, train_loss_step=1.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  20%|██        | 10/50 [00:04<00:18,  2.13it/s, v_num=4, train_loss_step=1.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  20%|██        | 10/50 [00:04<00:18,  2.13it/s, v_num=4, train_loss_step=1.81e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  22%|██▏       | 11/50 [00:05<00:18,  2.13it/s, v_num=4, train_loss_step=1.81e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  22%|██▏       | 11/50 [00:05<00:18,  2.13it/s, v_num=4, train_loss_step=1.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  24%|██▍       | 12/50 [00:05<00:17,  2.13it/s, v_num=4, train_loss_step=1.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  24%|██▍       | 12/50 [00:05<00:17,  2.13it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  26%|██▌       | 13/50 [00:06<00:17,  2.14it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  26%|██▌       | 13/50 [00:06<00:17,  2.14it/s, v_num=4, train_loss_step=2.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  28%|██▊       | 14/50 [00:06<00:16,  2.14it/s, v_num=4, train_loss_step=2.37e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  28%|██▊       | 14/50 [00:06<00:16,  2.13it/s, v_num=4, train_loss_step=3.67e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  30%|███       | 15/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=3.67e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  30%|███       | 15/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  32%|███▏      | 16/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=2.92e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  32%|███▏      | 16/50 [00:07<00:16,  2.12it/s, v_num=4, train_loss_step=1.93e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  34%|███▍      | 17/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=1.93e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  34%|███▍      | 17/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=3.86e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  36%|███▌      | 18/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=3.86e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  36%|███▌      | 18/50 [00:08<00:15,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  38%|███▊      | 19/50 [00:08<00:14,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  38%|███▊      | 19/50 [00:08<00:14,  2.12it/s, v_num=4, train_loss_step=1.96e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  40%|████      | 20/50 [00:09<00:14,  2.12it/s, v_num=4, train_loss_step=1.96e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  40%|████      | 20/50 [00:09<00:14,  2.12it/s, v_num=4, train_loss_step=2.2e+3, val_loss=485.0, train_loss_epoch=2.49e+3] Epoch 3:  42%|████▏     | 21/50 [00:09<00:13,  2.12it/s, v_num=4, train_loss_step=2.2e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  42%|████▏     | 21/50 [00:09<00:13,  2.12it/s, v_num=4, train_loss_step=2.55e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  44%|████▍     | 22/50 [00:10<00:13,  2.12it/s, v_num=4, train_loss_step=2.55e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  44%|████▍     | 22/50 [00:10<00:13,  2.12it/s, v_num=4, train_loss_step=2.42e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  46%|████▌     | 23/50 [00:10<00:12,  2.12it/s, v_num=4, train_loss_step=2.42e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  46%|████▌     | 23/50 [00:10<00:12,  2.12it/s, v_num=4, train_loss_step=2.98e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  48%|████▊     | 24/50 [00:11<00:12,  2.12it/s, v_num=4, train_loss_step=2.98e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  48%|████▊     | 24/50 [00:11<00:12,  2.12it/s, v_num=4, train_loss_step=3.21e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  50%|█████     | 25/50 [00:11<00:11,  2.12it/s, v_num=4, train_loss_step=3.21e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  50%|█████     | 25/50 [00:11<00:11,  2.12it/s, v_num=4, train_loss_step=2.66e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  52%|█████▏    | 26/50 [00:12<00:11,  2.12it/s, v_num=4, train_loss_step=2.66e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  52%|█████▏    | 26/50 [00:12<00:11,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  54%|█████▍    | 27/50 [00:12<00:10,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  54%|█████▍    | 27/50 [00:12<00:10,  2.12it/s, v_num=4, train_loss_step=2.64e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  56%|█████▌    | 28/50 [00:13<00:10,  2.12it/s, v_num=4, train_loss_step=2.64e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  56%|█████▌    | 28/50 [00:13<00:10,  2.12it/s, v_num=4, train_loss_step=2.17e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  58%|█████▊    | 29/50 [00:13<00:09,  2.12it/s, v_num=4, train_loss_step=2.17e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  58%|█████▊    | 29/50 [00:13<00:09,  2.12it/s, v_num=4, train_loss_step=2e+3, val_loss=485.0, train_loss_epoch=2.49e+3]   Epoch 3:  60%|██████    | 30/50 [00:14<00:09,  2.13it/s, v_num=4, train_loss_step=2e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  60%|██████    | 30/50 [00:14<00:09,  2.12it/s, v_num=4, train_loss_step=2.71e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  62%|██████▏   | 31/50 [00:14<00:08,  2.12it/s, v_num=4, train_loss_step=2.71e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  62%|██████▏   | 31/50 [00:14<00:08,  2.12it/s, v_num=4, train_loss_step=1.82e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  64%|██████▍   | 32/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=1.82e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  64%|██████▍   | 32/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  66%|██████▌   | 33/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=3.03e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  66%|██████▌   | 33/50 [00:15<00:08,  2.12it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]   Epoch 3:  68%|██████▊   | 34/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=3e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  68%|██████▊   | 34/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=2.76e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  70%|███████   | 35/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=2.76e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  70%|███████   | 35/50 [00:16<00:07,  2.12it/s, v_num=4, train_loss_step=1.41e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  72%|███████▏  | 36/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=1.41e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  72%|███████▏  | 36/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=2.9e+3, val_loss=485.0, train_loss_epoch=2.49e+3] Epoch 3:  74%|███████▍  | 37/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=2.9e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  74%|███████▍  | 37/50 [00:17<00:06,  2.12it/s, v_num=4, train_loss_step=2.63e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  76%|███████▌  | 38/50 [00:17<00:05,  2.12it/s, v_num=4, train_loss_step=2.63e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  76%|███████▌  | 38/50 [00:17<00:05,  2.12it/s, v_num=4, train_loss_step=1.97e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  78%|███████▊  | 39/50 [00:18<00:05,  2.12it/s, v_num=4, train_loss_step=1.97e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  78%|███████▊  | 39/50 [00:18<00:05,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  80%|████████  | 40/50 [00:18<00:04,  2.12it/s, v_num=4, train_loss_step=2.74e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  80%|████████  | 40/50 [00:18<00:04,  2.12it/s, v_num=4, train_loss_step=2.49e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  82%|████████▏ | 41/50 [00:19<00:04,  2.12it/s, v_num=4, train_loss_step=2.49e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  82%|████████▏ | 41/50 [00:19<00:04,  2.12it/s, v_num=4, train_loss_step=2.47e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  84%|████████▍ | 42/50 [00:19<00:03,  2.10it/s, v_num=4, train_loss_step=2.47e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  84%|████████▍ | 42/50 [00:20<00:03,  2.10it/s, v_num=4, train_loss_step=3.51e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  86%|████████▌ | 43/50 [00:20<00:03,  2.10it/s, v_num=4, train_loss_step=3.51e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  86%|████████▌ | 43/50 [00:20<00:03,  2.10it/s, v_num=4, train_loss_step=2.83e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  88%|████████▊ | 44/50 [00:20<00:02,  2.10it/s, v_num=4, train_loss_step=2.83e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  88%|████████▊ | 44/50 [00:20<00:02,  2.10it/s, v_num=4, train_loss_step=3.28e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  90%|█████████ | 45/50 [00:21<00:02,  2.10it/s, v_num=4, train_loss_step=3.28e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  90%|█████████ | 45/50 [00:21<00:02,  2.10it/s, v_num=4, train_loss_step=3.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  92%|█████████▏| 46/50 [00:21<00:01,  2.10it/s, v_num=4, train_loss_step=3.45e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  92%|█████████▏| 46/50 [00:21<00:01,  2.10it/s, v_num=4, train_loss_step=2.36e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  94%|█████████▍| 47/50 [00:22<00:01,  2.10it/s, v_num=4, train_loss_step=2.36e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  94%|█████████▍| 47/50 [00:22<00:01,  2.10it/s, v_num=4, train_loss_step=2.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  96%|█████████▌| 48/50 [00:22<00:00,  2.11it/s, v_num=4, train_loss_step=2.57e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  96%|█████████▌| 48/50 [00:22<00:00,  2.11it/s, v_num=4, train_loss_step=1.99e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  98%|█████████▊| 49/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=1.99e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3:  98%|█████████▊| 49/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=3.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3: 100%|██████████| 50/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=3.72e+3, val_loss=485.0, train_loss_epoch=2.49e+3]Epoch 3: 100%|██████████| 50/50 [00:23<00:00,  2.11it/s, v_num=4, train_loss_step=3.35e+3, val_loss=485.0, train_loss_epoch=2.49e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s][A
                                                                      [AEpoch 3: 100%|██████████| 50/50 [00:25<00:00,  1.99it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.49e+3]Epoch 3: 100%|██████████| 50/50 [00:25<00:00,  1.99it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]         Epoch 4:   0%|          | 0/50 [00:00<?, ?it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   2%|▏         | 1/50 [00:00<00:22,  2.16it/s, v_num=4, train_loss_step=3.35e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   2%|▏         | 1/50 [00:00<00:23,  2.08it/s, v_num=4, train_loss_step=2.21e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   4%|▍         | 2/50 [00:00<00:23,  2.06it/s, v_num=4, train_loss_step=2.21e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   4%|▍         | 2/50 [00:00<00:23,  2.01it/s, v_num=4, train_loss_step=2.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   6%|▌         | 3/50 [00:01<00:22,  2.06it/s, v_num=4, train_loss_step=2.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   6%|▌         | 3/50 [00:01<00:23,  2.03it/s, v_num=4, train_loss_step=1.7e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:   8%|▊         | 4/50 [00:01<00:22,  2.05it/s, v_num=4, train_loss_step=1.7e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:   8%|▊         | 4/50 [00:01<00:22,  2.05it/s, v_num=4, train_loss_step=1.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  10%|█         | 5/50 [00:02<00:22,  2.04it/s, v_num=4, train_loss_step=1.37e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  10%|█         | 5/50 [00:02<00:22,  2.04it/s, v_num=4, train_loss_step=1.55e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  12%|█▏        | 6/50 [00:02<00:21,  2.04it/s, v_num=4, train_loss_step=1.55e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  12%|█▏        | 6/50 [00:02<00:21,  2.03it/s, v_num=4, train_loss_step=2.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  14%|█▍        | 7/50 [00:03<00:20,  2.05it/s, v_num=4, train_loss_step=2.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  14%|█▍        | 7/50 [00:03<00:21,  2.04it/s, v_num=4, train_loss_step=2.22e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  16%|█▌        | 8/50 [00:03<00:20,  2.05it/s, v_num=4, train_loss_step=2.22e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  16%|█▌        | 8/50 [00:03<00:20,  2.05it/s, v_num=4, train_loss_step=2.02e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  18%|█▊        | 9/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=2.02e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  18%|█▊        | 9/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=1.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  20%|██        | 10/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=1.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  20%|██        | 10/50 [00:04<00:19,  2.07it/s, v_num=4, train_loss_step=3.03e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  22%|██▏       | 11/50 [00:05<00:18,  2.09it/s, v_num=4, train_loss_step=3.03e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  22%|██▏       | 11/50 [00:05<00:18,  2.09it/s, v_num=4, train_loss_step=2.39e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  24%|██▍       | 12/50 [00:05<00:18,  2.10it/s, v_num=4, train_loss_step=2.39e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  24%|██▍       | 12/50 [00:05<00:18,  2.10it/s, v_num=4, train_loss_step=2.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  26%|██▌       | 13/50 [00:06<00:17,  2.11it/s, v_num=4, train_loss_step=2.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  26%|██▌       | 13/50 [00:06<00:17,  2.11it/s, v_num=4, train_loss_step=1.64e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  28%|██▊       | 14/50 [00:06<00:17,  2.10it/s, v_num=4, train_loss_step=1.64e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  28%|██▊       | 14/50 [00:06<00:17,  2.10it/s, v_num=4, train_loss_step=2.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  30%|███       | 15/50 [00:07<00:16,  2.10it/s, v_num=4, train_loss_step=2.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  30%|███       | 15/50 [00:07<00:16,  2.10it/s, v_num=4, train_loss_step=2.78e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  32%|███▏      | 16/50 [00:07<00:16,  2.10it/s, v_num=4, train_loss_step=2.78e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  32%|███▏      | 16/50 [00:07<00:16,  2.09it/s, v_num=4, train_loss_step=3.43e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  34%|███▍      | 17/50 [00:08<00:15,  2.10it/s, v_num=4, train_loss_step=3.43e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  34%|███▍      | 17/50 [00:08<00:15,  2.09it/s, v_num=4, train_loss_step=3.4e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:  36%|███▌      | 18/50 [00:08<00:15,  2.10it/s, v_num=4, train_loss_step=3.4e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  36%|███▌      | 18/50 [00:08<00:15,  2.09it/s, v_num=4, train_loss_step=2.11e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  38%|███▊      | 19/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.11e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  38%|███▊      | 19/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  40%|████      | 20/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  40%|████      | 20/50 [00:09<00:14,  2.09it/s, v_num=4, train_loss_step=2.38e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  42%|████▏     | 21/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=2.38e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  42%|████▏     | 21/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=3.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  44%|████▍     | 22/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=3.56e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  44%|████▍     | 22/50 [00:10<00:13,  2.09it/s, v_num=4, train_loss_step=2.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  46%|████▌     | 23/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  46%|████▌     | 23/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.48e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  48%|████▊     | 24/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.48e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  48%|████▊     | 24/50 [00:11<00:12,  2.09it/s, v_num=4, train_loss_step=2.68e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  50%|█████     | 25/50 [00:11<00:11,  2.09it/s, v_num=4, train_loss_step=2.68e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  50%|█████     | 25/50 [00:11<00:11,  2.09it/s, v_num=4, train_loss_step=1.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  52%|█████▏    | 26/50 [00:12<00:11,  2.10it/s, v_num=4, train_loss_step=1.65e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  52%|█████▏    | 26/50 [00:12<00:11,  2.10it/s, v_num=4, train_loss_step=1.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  54%|█████▍    | 27/50 [00:12<00:10,  2.10it/s, v_num=4, train_loss_step=1.54e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  54%|█████▍    | 27/50 [00:12<00:10,  2.10it/s, v_num=4, train_loss_step=2.14e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  56%|█████▌    | 28/50 [00:13<00:10,  2.10it/s, v_num=4, train_loss_step=2.14e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  56%|█████▌    | 28/50 [00:13<00:10,  2.10it/s, v_num=4, train_loss_step=1.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  58%|█████▊    | 29/50 [00:13<00:10,  2.10it/s, v_num=4, train_loss_step=1.58e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  58%|█████▊    | 29/50 [00:13<00:10,  2.09it/s, v_num=4, train_loss_step=1.57e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  60%|██████    | 30/50 [00:14<00:09,  2.09it/s, v_num=4, train_loss_step=1.57e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  60%|██████    | 30/50 [00:14<00:09,  2.09it/s, v_num=4, train_loss_step=1.52e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  62%|██████▏   | 31/50 [00:14<00:09,  2.09it/s, v_num=4, train_loss_step=1.52e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  62%|██████▏   | 31/50 [00:14<00:09,  2.08it/s, v_num=4, train_loss_step=2.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  64%|██████▍   | 32/50 [00:15<00:08,  2.08it/s, v_num=4, train_loss_step=2.87e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  64%|██████▍   | 32/50 [00:15<00:08,  2.07it/s, v_num=4, train_loss_step=2.9e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:  66%|██████▌   | 33/50 [00:15<00:08,  2.08it/s, v_num=4, train_loss_step=2.9e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  66%|██████▌   | 33/50 [00:15<00:08,  2.07it/s, v_num=4, train_loss_step=2.82e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  68%|██████▊   | 34/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=2.82e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  68%|██████▊   | 34/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=3.27e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  70%|███████   | 35/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=3.27e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  70%|███████   | 35/50 [00:16<00:07,  2.07it/s, v_num=4, train_loss_step=2.13e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  72%|███████▏  | 36/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=2.13e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  72%|███████▏  | 36/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=3.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  74%|███████▍  | 37/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=3.77e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  74%|███████▍  | 37/50 [00:17<00:06,  2.07it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  76%|███████▌  | 38/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  76%|███████▌  | 38/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=1.93e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  78%|███████▊  | 39/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=1.93e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  78%|███████▊  | 39/50 [00:18<00:05,  2.07it/s, v_num=4, train_loss_step=3.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  80%|████████  | 40/50 [00:19<00:04,  2.07it/s, v_num=4, train_loss_step=3.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  80%|████████  | 40/50 [00:19<00:04,  2.07it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  82%|████████▏ | 41/50 [00:19<00:04,  2.08it/s, v_num=4, train_loss_step=2.36e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  82%|████████▏ | 41/50 [00:19<00:04,  2.08it/s, v_num=4, train_loss_step=4.72e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  84%|████████▍ | 42/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=4.72e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  84%|████████▍ | 42/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=2.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  86%|████████▌ | 43/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=2.01e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  86%|████████▌ | 43/50 [00:20<00:03,  2.08it/s, v_num=4, train_loss_step=1.96e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  88%|████████▊ | 44/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=1.96e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  88%|████████▊ | 44/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=2.1e+3, val_loss=499.0, train_loss_epoch=2.57e+3] Epoch 4:  90%|█████████ | 45/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=2.1e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  90%|█████████ | 45/50 [00:21<00:02,  2.08it/s, v_num=4, train_loss_step=2.44e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  92%|█████████▏| 46/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=2.44e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  92%|█████████▏| 46/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=3.53e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  94%|█████████▍| 47/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=3.53e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  94%|█████████▍| 47/50 [00:22<00:01,  2.09it/s, v_num=4, train_loss_step=2.09e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  96%|█████████▌| 48/50 [00:22<00:00,  2.09it/s, v_num=4, train_loss_step=2.09e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  96%|█████████▌| 48/50 [00:22<00:00,  2.09it/s, v_num=4, train_loss_step=2.84e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  98%|█████████▊| 49/50 [00:23<00:00,  2.09it/s, v_num=4, train_loss_step=2.84e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4:  98%|█████████▊| 49/50 [00:23<00:00,  2.09it/s, v_num=4, train_loss_step=1.83e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4: 100%|██████████| 50/50 [00:23<00:00,  2.10it/s, v_num=4, train_loss_step=1.83e+3, val_loss=499.0, train_loss_epoch=2.57e+3]Epoch 4: 100%|██████████| 50/50 [00:23<00:00,  2.10it/s, v_num=4, train_loss_step=2.73e+3, val_loss=499.0, train_loss_epoch=2.57e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s][A
                                                                      [AEpoch 4: 100%|██████████| 50/50 [00:25<00:00,  1.97it/s, v_num=4, train_loss_step=2.73e+3, val_loss=516.0, train_loss_epoch=2.57e+3]Epoch 4: 100%|██████████| 50/50 [00:25<00:00,  1.97it/s, v_num=4, train_loss_step=2.73e+3, val_loss=516.0, train_loss_epoch=2.44e+3]`Trainer.fit` stopped: `max_epochs=5` reached.
Epoch 4: 100%|██████████| 50/50 [00:25<00:00,  1.96it/s, v_num=4, train_loss_step=2.73e+3, val_loss=516.0, train_loss_epoch=2.44e+3] * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node2.py', reloading

 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node2.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node1.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node1.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node1.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node2.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node4.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node4.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node6.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node7.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/cs/grad/sokhanka/miniconda3/envs/data-science/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 569-604-976
 * Detected change in '/home/cs/grad/sokhanka/Documents/DigitalTwin/run.py', reloading
 * Restarting with stat
/home/cs/grad/sokhanka/miniconda3/envs/data-science/bin/python3: can't open file '/home/cs/grad/sokhanka/Documents/DigitalTwin/nodes/node8.py': [Errno 2] No such file or directory
