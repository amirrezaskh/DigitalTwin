/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Serving Flask app 'node1'
 * Debug mode: on
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://localhost:8001
[33mPress CTRL+C to quit[0m
 * Restarting with stat
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 868-625-521
127.0.0.1 - - [05/Jun/2025 22:13:17] "GET /train/ HTTP/1.1" 200 -
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]Finding best initial lr:   1%|          | 1/100 [00:07<12:19,  7.47s/it]Finding best initial lr:   2%|â–         | 2/100 [00:09<07:24,  4.54s/it]Finding best initial lr:   3%|â–Ž         | 3/100 [00:12<06:00,  3.72s/it]Finding best initial lr:   4%|â–         | 4/100 [00:15<05:15,  3.29s/it]Finding best initial lr:   5%|â–Œ         | 5/100 [00:18<05:03,  3.19s/it]Finding best initial lr:   6%|â–Œ         | 6/100 [00:20<04:15,  2.72s/it]Finding best initial lr:   7%|â–‹         | 7/100 [00:22<03:58,  2.57s/it]Finding best initial lr:   8%|â–Š         | 8/100 [00:25<04:07,  2.69s/it]Finding best initial lr:   9%|â–‰         | 9/100 [00:28<04:05,  2.70s/it]Finding best initial lr:  10%|â–ˆ         | 10/100 [00:30<03:49,  2.55s/it]Finding best initial lr:  11%|â–ˆ         | 11/100 [00:32<03:48,  2.57s/it]Finding best initial lr:  12%|â–ˆâ–        | 12/100 [00:35<03:54,  2.67s/it]Finding best initial lr:  13%|â–ˆâ–Ž        | 13/100 [00:38<03:53,  2.69s/it]Finding best initial lr:  14%|â–ˆâ–        | 14/100 [00:41<04:04,  2.84s/it]Finding best initial lr:  15%|â–ˆâ–Œ        | 15/100 [00:44<03:58,  2.81s/it]Finding best initial lr:  16%|â–ˆâ–Œ        | 16/100 [00:46<03:36,  2.58s/it]Finding best initial lr:  17%|â–ˆâ–‹        | 17/100 [00:49<03:39,  2.64s/it]Finding best initial lr:  18%|â–ˆâ–Š        | 18/100 [00:52<03:40,  2.69s/it]Finding best initial lr:  19%|â–ˆâ–‰        | 19/100 [00:54<03:36,  2.68s/it]Finding best initial lr:  20%|â–ˆâ–ˆ        | 20/100 [00:56<03:22,  2.53s/it]Finding best initial lr:  21%|â–ˆâ–ˆ        | 21/100 [00:59<03:26,  2.61s/it]Finding best initial lr:  22%|â–ˆâ–ˆâ–       | 22/100 [01:02<03:17,  2.53s/it]Finding best initial lr:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [01:04<03:14,  2.52s/it]Finding best initial lr:  24%|â–ˆâ–ˆâ–       | 24/100 [01:06<02:59,  2.36s/it]Finding best initial lr:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [01:09<03:14,  2.59s/it]Finding best initial lr:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [01:12<03:19,  2.70s/it]Finding best initial lr:  27%|â–ˆâ–ˆâ–‹       | 27/100 [01:15<03:24,  2.80s/it]Finding best initial lr:  28%|â–ˆâ–ˆâ–Š       | 28/100 [01:18<03:17,  2.74s/it]Finding best initial lr:  29%|â–ˆâ–ˆâ–‰       | 29/100 [01:21<03:25,  2.89s/it]Finding best initial lr:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [01:24<03:18,  2.84s/it]Finding best initial lr:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [01:26<03:11,  2.78s/it]Finding best initial lr:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [01:29<03:14,  2.86s/it]Finding best initial lr:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [01:32<03:09,  2.83s/it]Finding best initial lr:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [01:35<03:07,  2.83s/it]Finding best initial lr:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [01:37<02:54,  2.68s/it]Finding best initial lr:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [01:42<03:20,  3.14s/it]Finding best initial lr:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [01:45<03:21,  3.19s/it]Finding best initial lr:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [01:47<03:03,  2.97s/it]Finding best initial lr:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [01:50<02:55,  2.88s/it]Finding best initial lr:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [01:53<03:01,  3.02s/it]Finding best initial lr:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [01:57<03:07,  3.17s/it]Finding best initial lr:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [02:00<02:57,  3.07s/it]Finding best initial lr:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [02:03<03:07,  3.29s/it]Finding best initial lr:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [02:06<02:55,  3.13s/it]Finding best initial lr:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [02:09<02:39,  2.89s/it]Finding best initial lr:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [02:12<02:43,  3.03s/it]Finding best initial lr:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [02:16<02:55,  3.31s/it]Finding best initial lr:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [02:19<02:45,  3.18s/it]Finding best initial lr:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [02:22<02:39,  3.14s/it]Finding best initial lr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [02:25<02:31,  3.03s/it]Finding best initial lr:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [02:32<03:28,  4.25s/it]Finding best initial lr:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [02:36<03:20,  4.17s/it]Finding best initial lr:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [02:39<03:01,  3.87s/it]Finding best initial lr:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [02:42<02:50,  3.71s/it]Finding best initial lr:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [02:46<02:53,  3.85s/it]Finding best initial lr:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [02:49<02:38,  3.61s/it]Finding best initial lr:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [02:53<02:36,  3.65s/it]Finding best initial lr:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [02:56<02:25,  3.47s/it]Finding best initial lr:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [02:59<02:11,  3.21s/it]Finding best initial lr:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [03:01<01:54,  2.86s/it]Finding best initial lr:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [03:04<02:00,  3.08s/it]Finding best initial lr:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [03:07<01:55,  3.03s/it]Finding best initial lr:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [03:10<01:43,  2.79s/it]Finding best initial lr:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [03:12<01:36,  2.69s/it]Finding best initial lr:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [03:15<01:41,  2.89s/it]Finding best initial lr:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [03:19<01:40,  2.96s/it]Finding best initial lr:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [03:21<01:31,  2.78s/it]Finding best initial lr:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [03:24<01:33,  2.92s/it]Finding best initial lr:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [03:27<01:27,  2.83s/it]Finding best initial lr:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [03:32<01:42,  3.42s/it]Finding best initial lr:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [03:36<01:48,  3.74s/it]Finding best initial lr:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [03:41<01:56,  4.16s/it]Finding best initial lr:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [03:47<02:06,  4.68s/it]Finding best initial lr:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [03:51<01:55,  4.43s/it]Finding best initial lr:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [03:55<01:48,  4.33s/it]Finding best initial lr:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [03:59<01:41,  4.24s/it]Finding best initial lr:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [04:02<01:28,  3.86s/it]Finding best initial lr:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [04:06<01:23,  3.77s/it]Finding best initial lr:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [04:09<01:18,  3.75s/it]Finding best initial lr:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [04:12<01:11,  3.55s/it]Finding best initial lr:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [04:16<01:08,  3.62s/it]Finding best initial lr:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [04:20<01:06,  3.69s/it]Finding best initial lr:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [04:23<01:01,  3.60s/it]Finding best initial lr:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [04:27<00:55,  3.49s/it]Finding best initial lr:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [04:30<00:50,  3.38s/it]Finding best initial lr:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [04:33<00:45,  3.23s/it]Finding best initial lr:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [04:35<00:37,  2.91s/it]Finding best initial lr:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [04:40<00:44,  3.69s/it]Finding best initial lr:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [04:44<00:39,  3.56s/it]Finding best initial lr:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [04:47<00:33,  3.40s/it]Finding best initial lr:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [04:47<00:31,  3.19s/it]
LR finder stopped early after 90 steps due to diverging loss.
Learning rate set to 0.01862087136662867
Restoring states from the checkpoint path at /Users/amirrezasokhankhosh/Documents/Workstation/DigitalTwin/nodes/.lr_find_91a1d87c-a60b-4839-90ff-563d9f69384d.ckpt
Restored all states from the checkpoint at /Users/amirrezasokhankhosh/Documents/Workstation/DigitalTwin/nodes/.lr_find_91a1d87c-a60b-4839-90ff-563d9f69384d.ckpt

   | Name                               | Type                            | Params | Mode 
------------------------------------------------------------------------------------------------
0  | loss                               | MultiLoss                       | 0      | train
1  | logging_metrics                    | ModuleList                      | 0      | train
2  | input_embeddings                   | MultiEmbedding                  | 630    | train
3  | prescalers                         | ModuleDict                      | 288    | train
4  | static_variable_selection          | VariableSelectionNetwork        | 8.3 K  | train
5  | encoder_variable_selection         | VariableSelectionNetwork        | 4.4 K  | train
6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.6 K  | train
7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train
8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train
9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train
10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train
11 | lstm_encoder                       | LSTM                            | 2.2 K  | train
12 | lstm_decoder                       | LSTM                            | 2.2 K  | train
13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train
14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train
15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train
16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K  | train
17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train
18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train
19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train
20 | output_layer                       | ModuleList                      | 68     | train
------------------------------------------------------------------------------------------------
29.1 K    Trainable params
0         Non-trainable params
29.1 K    Total params
0.116     Total estimated model params size (MB)
489       Modules in train mode
0         Modules in eval mode
Sanity Checking: |          | 0/? [00:00<?, ?it/s]/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  0.58it/s]                                                                           /Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/50 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s] Epoch 0:   2%|â–         | 1/50 [00:02<02:21,  0.35it/s]Epoch 0:   2%|â–         | 1/50 [00:02<02:21,  0.35it/s, v_num=2, train_loss_step=2.17e+4]Epoch 0:   4%|â–         | 2/50 [00:05<02:12,  0.36it/s, v_num=2, train_loss_step=2.17e+4]Epoch 0:   4%|â–         | 2/50 [00:05<02:12,  0.36it/s, v_num=2, train_loss_step=1.97e+4]Epoch 0:   6%|â–Œ         | 3/50 [00:09<02:27,  0.32it/s, v_num=2, train_loss_step=1.97e+4]Epoch 0:   6%|â–Œ         | 3/50 [00:09<02:27,  0.32it/s, v_num=2, train_loss_step=1.94e+4]Epoch 0:   8%|â–Š         | 4/50 [00:13<02:32,  0.30it/s, v_num=2, train_loss_step=1.94e+4]Epoch 0:   8%|â–Š         | 4/50 [00:13<02:32,  0.30it/s, v_num=2, train_loss_step=1.54e+4]Epoch 0:  10%|â–ˆ         | 5/50 [00:16<02:31,  0.30it/s, v_num=2, train_loss_step=1.54e+4]Epoch 0:  10%|â–ˆ         | 5/50 [00:16<02:31,  0.30it/s, v_num=2, train_loss_step=1.29e+4]Epoch 0:  12%|â–ˆâ–        | 6/50 [00:21<02:35,  0.28it/s, v_num=2, train_loss_step=1.29e+4]Epoch 0:  12%|â–ˆâ–        | 6/50 [00:21<02:35,  0.28it/s, v_num=2, train_loss_step=1.02e+4]Epoch 0:  14%|â–ˆâ–        | 7/50 [00:24<02:28,  0.29it/s, v_num=2, train_loss_step=1.02e+4]Epoch 0:  14%|â–ˆâ–        | 7/50 [00:24<02:28,  0.29it/s, v_num=2, train_loss_step=7.25e+3]Epoch 0:  16%|â–ˆâ–Œ        | 8/50 [00:28<02:27,  0.28it/s, v_num=2, train_loss_step=7.25e+3]Epoch 0:  16%|â–ˆâ–Œ        | 8/50 [00:28<02:27,  0.28it/s, v_num=2, train_loss_step=4.93e+3]Epoch 0:  18%|â–ˆâ–Š        | 9/50 [00:31<02:24,  0.28it/s, v_num=2, train_loss_step=4.93e+3]Epoch 0:  18%|â–ˆâ–Š        | 9/50 [00:31<02:24,  0.28it/s, v_num=2, train_loss_step=4.02e+3]Epoch 0:  20%|â–ˆâ–ˆ        | 10/50 [00:34<02:18,  0.29it/s, v_num=2, train_loss_step=4.02e+3]Epoch 0:  20%|â–ˆâ–ˆ        | 10/50 [00:34<02:18,  0.29it/s, v_num=2, train_loss_step=2.77e+3]Epoch 0:  22%|â–ˆâ–ˆâ–       | 11/50 [00:37<02:14,  0.29it/s, v_num=2, train_loss_step=2.77e+3]Epoch 0:  22%|â–ˆâ–ˆâ–       | 11/50 [00:37<02:14,  0.29it/s, v_num=2, train_loss_step=2.07e+3]Epoch 0:  24%|â–ˆâ–ˆâ–       | 12/50 [00:40<02:08,  0.30it/s, v_num=2, train_loss_step=2.07e+3]Epoch 0:  24%|â–ˆâ–ˆâ–       | 12/50 [00:40<02:08,  0.30it/s, v_num=2, train_loss_step=1.89e+3]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:43<02:04,  0.30it/s, v_num=2, train_loss_step=1.89e+3]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:43<02:04,  0.30it/s, v_num=2, train_loss_step=1e+3]   Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:48<02:03,  0.29it/s, v_num=2, train_loss_step=1e+3]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:48<02:03,  0.29it/s, v_num=2, train_loss_step=931.0]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:51<02:00,  0.29it/s, v_num=2, train_loss_step=931.0]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:51<02:00,  0.29it/s, v_num=2, train_loss_step=945.0]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:55<01:56,  0.29it/s, v_num=2, train_loss_step=945.0]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:55<01:56,  0.29it/s, v_num=2, train_loss_step=893.0]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:59<01:55,  0.29it/s, v_num=2, train_loss_step=893.0]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:59<01:55,  0.29it/s, v_num=2, train_loss_step=616.0]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:02<01:50,  0.29it/s, v_num=2, train_loss_step=616.0]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:02<01:50,  0.29it/s, v_num=2, train_loss_step=543.0]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:05<01:46,  0.29it/s, v_num=2, train_loss_step=543.0]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:05<01:46,  0.29it/s, v_num=2, train_loss_step=505.0]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:09<01:43,  0.29it/s, v_num=2, train_loss_step=505.0]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:09<01:43,  0.29it/s, v_num=2, train_loss_step=372.0]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:13<01:41,  0.29it/s, v_num=2, train_loss_step=372.0]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:13<01:41,  0.29it/s, v_num=2, train_loss_step=316.0]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:18<01:39,  0.28it/s, v_num=2, train_loss_step=316.0]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:18<01:39,  0.28it/s, v_num=2, train_loss_step=269.0]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:22<01:36,  0.28it/s, v_num=2, train_loss_step=269.0]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:22<01:36,  0.28it/s, v_num=2, train_loss_step=261.0]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:25<01:32,  0.28it/s, v_num=2, train_loss_step=261.0]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:25<01:32,  0.28it/s, v_num=2, train_loss_step=181.0]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:28<01:28,  0.28it/s, v_num=2, train_loss_step=181.0]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:28<01:28,  0.28it/s, v_num=2, train_loss_step=174.0]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:32<01:25,  0.28it/s, v_num=2, train_loss_step=174.0]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:32<01:25,  0.28it/s, v_num=2, train_loss_step=182.0]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:35<01:21,  0.28it/s, v_num=2, train_loss_step=182.0]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:35<01:21,  0.28it/s, v_num=2, train_loss_step=134.0]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:39<01:17,  0.28it/s, v_num=2, train_loss_step=134.0]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:39<01:17,  0.28it/s, v_num=2, train_loss_step=183.0]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:43<01:14,  0.28it/s, v_num=2, train_loss_step=183.0]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:43<01:14,  0.28it/s, v_num=2, train_loss_step=193.0]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:46<01:11,  0.28it/s, v_num=2, train_loss_step=193.0]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:46<01:11,  0.28it/s, v_num=2, train_loss_step=166.0]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:50<01:07,  0.28it/s, v_num=2, train_loss_step=166.0]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:50<01:07,  0.28it/s, v_num=2, train_loss_step=137.0]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:54<01:04,  0.28it/s, v_num=2, train_loss_step=137.0]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:54<01:04,  0.28it/s, v_num=2, train_loss_step=104.0]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:57<01:00,  0.28it/s, v_num=2, train_loss_step=104.0]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:57<01:00,  0.28it/s, v_num=2, train_loss_step=108.0]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:01<00:56,  0.28it/s, v_num=2, train_loss_step=108.0]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:01<00:56,  0.28it/s, v_num=2, train_loss_step=94.60]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:04<00:53,  0.28it/s, v_num=2, train_loss_step=94.60]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:04<00:53,  0.28it/s, v_num=2, train_loss_step=79.00]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:07<00:49,  0.28it/s, v_num=2, train_loss_step=79.00]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:07<00:49,  0.28it/s, v_num=2, train_loss_step=115.0]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:10<00:45,  0.28it/s, v_num=2, train_loss_step=115.0]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:10<00:45,  0.28it/s, v_num=2, train_loss_step=116.0]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:13<00:42,  0.28it/s, v_num=2, train_loss_step=116.0]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:13<00:42,  0.28it/s, v_num=2, train_loss_step=79.10]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:16<00:38,  0.29it/s, v_num=2, train_loss_step=79.10]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:16<00:38,  0.29it/s, v_num=2, train_loss_step=89.30]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:19<00:34,  0.29it/s, v_num=2, train_loss_step=89.30]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:19<00:34,  0.29it/s, v_num=2, train_loss_step=82.80]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:23<00:31,  0.29it/s, v_num=2, train_loss_step=82.80]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:23<00:31,  0.29it/s, v_num=2, train_loss_step=76.60]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:26<00:27,  0.29it/s, v_num=2, train_loss_step=76.60]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:26<00:27,  0.29it/s, v_num=2, train_loss_step=61.00]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:29<00:24,  0.29it/s, v_num=2, train_loss_step=61.00]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:29<00:24,  0.29it/s, v_num=2, train_loss_step=60.60]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:33<00:20,  0.29it/s, v_num=2, train_loss_step=60.60]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:33<00:20,  0.29it/s, v_num=2, train_loss_step=52.10]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:36<00:17,  0.29it/s, v_num=2, train_loss_step=52.10]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:36<00:17,  0.29it/s, v_num=2, train_loss_step=53.00]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:39<00:13,  0.29it/s, v_num=2, train_loss_step=53.00]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:39<00:13,  0.29it/s, v_num=2, train_loss_step=47.20]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:42<00:10,  0.29it/s, v_num=2, train_loss_step=47.20]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:42<00:10,  0.29it/s, v_num=2, train_loss_step=43.80]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:46<00:06,  0.29it/s, v_num=2, train_loss_step=43.80]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:46<00:06,  0.29it/s, v_num=2, train_loss_step=69.20]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:49<00:03,  0.29it/s, v_num=2, train_loss_step=69.20]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:49<00:03,  0.29it/s, v_num=2, train_loss_step=57.30]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:53<00:00,  0.29it/s, v_num=2, train_loss_step=57.30]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:53<00:00,  0.29it/s, v_num=2, train_loss_step=61.70]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  0.31it/s][A
                                                                      [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:56<00:00,  0.28it/s, v_num=2, train_loss_step=61.70, val_loss=33.90]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:56<00:00,  0.28it/s, v_num=2, train_loss_step=61.70, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=61.70, val_loss=33.90, train_loss_epoch=2.63e+3]         Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=61.70, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   2%|â–         | 1/50 [00:02<02:16,  0.36it/s, v_num=2, train_loss_step=61.70, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   2%|â–         | 1/50 [00:02<02:16,  0.36it/s, v_num=2, train_loss_step=61.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   4%|â–         | 2/50 [00:05<02:20,  0.34it/s, v_num=2, train_loss_step=61.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   4%|â–         | 2/50 [00:05<02:20,  0.34it/s, v_num=2, train_loss_step=43.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   6%|â–Œ         | 3/50 [00:10<02:37,  0.30it/s, v_num=2, train_loss_step=43.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   6%|â–Œ         | 3/50 [00:10<02:37,  0.30it/s, v_num=2, train_loss_step=47.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   8%|â–Š         | 4/50 [00:13<02:37,  0.29it/s, v_num=2, train_loss_step=47.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:   8%|â–Š         | 4/50 [00:13<02:38,  0.29it/s, v_num=2, train_loss_step=45.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  10%|â–ˆ         | 5/50 [00:17<02:40,  0.28it/s, v_num=2, train_loss_step=45.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  10%|â–ˆ         | 5/50 [00:17<02:40,  0.28it/s, v_num=2, train_loss_step=39.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  12%|â–ˆâ–        | 6/50 [00:21<02:38,  0.28it/s, v_num=2, train_loss_step=39.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  12%|â–ˆâ–        | 6/50 [00:21<02:38,  0.28it/s, v_num=2, train_loss_step=45.20, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  14%|â–ˆâ–        | 7/50 [00:25<02:35,  0.28it/s, v_num=2, train_loss_step=45.20, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  14%|â–ˆâ–        | 7/50 [00:25<02:35,  0.28it/s, v_num=2, train_loss_step=44.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  16%|â–ˆâ–Œ        | 8/50 [00:28<02:29,  0.28it/s, v_num=2, train_loss_step=44.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  16%|â–ˆâ–Œ        | 8/50 [00:28<02:29,  0.28it/s, v_num=2, train_loss_step=34.20, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  18%|â–ˆâ–Š        | 9/50 [00:31<02:25,  0.28it/s, v_num=2, train_loss_step=34.20, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  18%|â–ˆâ–Š        | 9/50 [00:31<02:25,  0.28it/s, v_num=2, train_loss_step=31.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  20%|â–ˆâ–ˆ        | 10/50 [00:35<02:22,  0.28it/s, v_num=2, train_loss_step=31.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  20%|â–ˆâ–ˆ        | 10/50 [00:35<02:22,  0.28it/s, v_num=2, train_loss_step=44.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  22%|â–ˆâ–ˆâ–       | 11/50 [00:38<02:17,  0.28it/s, v_num=2, train_loss_step=44.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  22%|â–ˆâ–ˆâ–       | 11/50 [00:38<02:17,  0.28it/s, v_num=2, train_loss_step=36.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  24%|â–ˆâ–ˆâ–       | 12/50 [00:42<02:13,  0.29it/s, v_num=2, train_loss_step=36.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  24%|â–ˆâ–ˆâ–       | 12/50 [00:42<02:13,  0.29it/s, v_num=2, train_loss_step=36.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:45<02:08,  0.29it/s, v_num=2, train_loss_step=36.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:45<02:08,  0.29it/s, v_num=2, train_loss_step=36.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:47<02:02,  0.29it/s, v_num=2, train_loss_step=36.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:47<02:02,  0.29it/s, v_num=2, train_loss_step=38.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:51<01:59,  0.29it/s, v_num=2, train_loss_step=38.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:51<01:59,  0.29it/s, v_num=2, train_loss_step=31.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:54<01:55,  0.29it/s, v_num=2, train_loss_step=31.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:54<01:55,  0.29it/s, v_num=2, train_loss_step=41.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:58<01:52,  0.29it/s, v_num=2, train_loss_step=41.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:58<01:52,  0.29it/s, v_num=2, train_loss_step=37.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:01<01:49,  0.29it/s, v_num=2, train_loss_step=37.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:01<01:49,  0.29it/s, v_num=2, train_loss_step=31.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:05<01:46,  0.29it/s, v_num=2, train_loss_step=31.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:05<01:46,  0.29it/s, v_num=2, train_loss_step=27.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:08<01:42,  0.29it/s, v_num=2, train_loss_step=27.10, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:08<01:42,  0.29it/s, v_num=2, train_loss_step=39.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:11<01:39,  0.29it/s, v_num=2, train_loss_step=39.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:11<01:39,  0.29it/s, v_num=2, train_loss_step=33.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:15<01:35,  0.29it/s, v_num=2, train_loss_step=33.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:15<01:35,  0.29it/s, v_num=2, train_loss_step=36.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:18<01:31,  0.29it/s, v_num=2, train_loss_step=36.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:18<01:31,  0.29it/s, v_num=2, train_loss_step=36.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:21<01:28,  0.29it/s, v_num=2, train_loss_step=36.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:21<01:28,  0.29it/s, v_num=2, train_loss_step=26.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:24<01:24,  0.30it/s, v_num=2, train_loss_step=26.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:24<01:24,  0.30it/s, v_num=2, train_loss_step=23.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:27<01:21,  0.30it/s, v_num=2, train_loss_step=23.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:27<01:21,  0.30it/s, v_num=2, train_loss_step=34.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:31<01:17,  0.30it/s, v_num=2, train_loss_step=34.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:31<01:17,  0.30it/s, v_num=2, train_loss_step=30.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:34<01:14,  0.30it/s, v_num=2, train_loss_step=30.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:34<01:14,  0.30it/s, v_num=2, train_loss_step=28.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:38<01:11,  0.30it/s, v_num=2, train_loss_step=28.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:38<01:11,  0.30it/s, v_num=2, train_loss_step=24.90, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:41<01:07,  0.30it/s, v_num=2, train_loss_step=24.90, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:41<01:07,  0.30it/s, v_num=2, train_loss_step=32.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:45<01:04,  0.30it/s, v_num=2, train_loss_step=32.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:45<01:04,  0.30it/s, v_num=2, train_loss_step=27.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:48<01:01,  0.29it/s, v_num=2, train_loss_step=27.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:48<01:01,  0.29it/s, v_num=2, train_loss_step=25.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:51<00:57,  0.30it/s, v_num=2, train_loss_step=25.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:51<00:57,  0.30it/s, v_num=2, train_loss_step=25.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [01:54<00:53,  0.30it/s, v_num=2, train_loss_step=25.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [01:54<00:53,  0.30it/s, v_num=2, train_loss_step=27.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [01:57<00:50,  0.30it/s, v_num=2, train_loss_step=27.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [01:57<00:50,  0.30it/s, v_num=2, train_loss_step=27.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:00<00:46,  0.30it/s, v_num=2, train_loss_step=27.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:00<00:46,  0.30it/s, v_num=2, train_loss_step=22.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:03<00:43,  0.30it/s, v_num=2, train_loss_step=22.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:03<00:43,  0.30it/s, v_num=2, train_loss_step=21.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:07<00:40,  0.30it/s, v_num=2, train_loss_step=21.60, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:07<00:40,  0.30it/s, v_num=2, train_loss_step=27.90, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:11<00:36,  0.30it/s, v_num=2, train_loss_step=27.90, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:11<00:36,  0.30it/s, v_num=2, train_loss_step=26.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:14<00:33,  0.30it/s, v_num=2, train_loss_step=26.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:14<00:33,  0.30it/s, v_num=2, train_loss_step=22.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:18<00:30,  0.30it/s, v_num=2, train_loss_step=22.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:18<00:30,  0.30it/s, v_num=2, train_loss_step=21.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:21<00:26,  0.30it/s, v_num=2, train_loss_step=21.00, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:21<00:26,  0.30it/s, v_num=2, train_loss_step=25.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:24<00:23,  0.30it/s, v_num=2, train_loss_step=25.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:24<00:23,  0.30it/s, v_num=2, train_loss_step=25.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:28<00:20,  0.30it/s, v_num=2, train_loss_step=25.30, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:28<00:20,  0.30it/s, v_num=2, train_loss_step=21.70, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:32<00:16,  0.30it/s, v_num=2, train_loss_step=21.70, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:32<00:16,  0.30it/s, v_num=2, train_loss_step=21.90, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:35<00:13,  0.30it/s, v_num=2, train_loss_step=21.90, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:35<00:13,  0.30it/s, v_num=2, train_loss_step=21.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:38<00:10,  0.30it/s, v_num=2, train_loss_step=21.50, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:38<00:10,  0.30it/s, v_num=2, train_loss_step=20.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:41<00:06,  0.30it/s, v_num=2, train_loss_step=20.40, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:41<00:06,  0.30it/s, v_num=2, train_loss_step=20.20, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:44<00:03,  0.30it/s, v_num=2, train_loss_step=20.20, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:44<00:03,  0.30it/s, v_num=2, train_loss_step=17.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:47<00:00,  0.30it/s, v_num=2, train_loss_step=17.80, val_loss=33.90, train_loss_epoch=2.63e+3]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:47<00:00,  0.30it/s, v_num=2, train_loss_step=23.20, val_loss=33.90, train_loss_epoch=2.63e+3]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  0.50it/s][A
                                                                      [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:49<00:00,  0.29it/s, v_num=2, train_loss_step=23.20, val_loss=10.90, train_loss_epoch=2.63e+3]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:49<00:00,  0.29it/s, v_num=2, train_loss_step=23.20, val_loss=10.90, train_loss_epoch=31.40]  Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=23.20, val_loss=10.90, train_loss_epoch=31.40]         Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=23.20, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   2%|â–         | 1/50 [00:02<01:51,  0.44it/s, v_num=2, train_loss_step=23.20, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   2%|â–         | 1/50 [00:02<01:51,  0.44it/s, v_num=2, train_loss_step=20.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   4%|â–         | 2/50 [00:06<02:26,  0.33it/s, v_num=2, train_loss_step=20.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   4%|â–         | 2/50 [00:06<02:26,  0.33it/s, v_num=2, train_loss_step=18.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   6%|â–Œ         | 3/50 [00:09<02:27,  0.32it/s, v_num=2, train_loss_step=18.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   6%|â–Œ         | 3/50 [00:09<02:27,  0.32it/s, v_num=2, train_loss_step=17.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   8%|â–Š         | 4/50 [00:12<02:22,  0.32it/s, v_num=2, train_loss_step=17.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:   8%|â–Š         | 4/50 [00:12<02:22,  0.32it/s, v_num=2, train_loss_step=23.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  10%|â–ˆ         | 5/50 [00:16<02:26,  0.31it/s, v_num=2, train_loss_step=23.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  10%|â–ˆ         | 5/50 [00:16<02:26,  0.31it/s, v_num=2, train_loss_step=21.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  12%|â–ˆâ–        | 6/50 [00:19<02:25,  0.30it/s, v_num=2, train_loss_step=21.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  12%|â–ˆâ–        | 6/50 [00:19<02:25,  0.30it/s, v_num=2, train_loss_step=17.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  14%|â–ˆâ–        | 7/50 [00:22<02:18,  0.31it/s, v_num=2, train_loss_step=17.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  14%|â–ˆâ–        | 7/50 [00:22<02:18,  0.31it/s, v_num=2, train_loss_step=17.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  16%|â–ˆâ–Œ        | 8/50 [00:26<02:16,  0.31it/s, v_num=2, train_loss_step=17.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  16%|â–ˆâ–Œ        | 8/50 [00:26<02:16,  0.31it/s, v_num=2, train_loss_step=17.70, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  18%|â–ˆâ–Š        | 9/50 [00:28<02:11,  0.31it/s, v_num=2, train_loss_step=17.70, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  18%|â–ˆâ–Š        | 9/50 [00:28<02:11,  0.31it/s, v_num=2, train_loss_step=18.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  20%|â–ˆâ–ˆ        | 10/50 [00:32<02:10,  0.31it/s, v_num=2, train_loss_step=18.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  20%|â–ˆâ–ˆ        | 10/50 [00:32<02:10,  0.31it/s, v_num=2, train_loss_step=18.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  22%|â–ˆâ–ˆâ–       | 11/50 [00:39<02:21,  0.28it/s, v_num=2, train_loss_step=18.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  22%|â–ˆâ–ˆâ–       | 11/50 [00:39<02:21,  0.28it/s, v_num=2, train_loss_step=17.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  24%|â–ˆâ–ˆâ–       | 12/50 [00:43<02:17,  0.28it/s, v_num=2, train_loss_step=17.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  24%|â–ˆâ–ˆâ–       | 12/50 [00:43<02:17,  0.28it/s, v_num=2, train_loss_step=18.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:47<02:15,  0.27it/s, v_num=2, train_loss_step=18.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:47<02:15,  0.27it/s, v_num=2, train_loss_step=18.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:51<02:12,  0.27it/s, v_num=2, train_loss_step=18.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:51<02:12,  0.27it/s, v_num=2, train_loss_step=17.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:54<02:06,  0.28it/s, v_num=2, train_loss_step=17.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:54<02:06,  0.28it/s, v_num=2, train_loss_step=17.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:57<02:02,  0.28it/s, v_num=2, train_loss_step=17.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:57<02:02,  0.28it/s, v_num=2, train_loss_step=17.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [01:02<02:01,  0.27it/s, v_num=2, train_loss_step=17.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [01:02<02:01,  0.27it/s, v_num=2, train_loss_step=16.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:06<01:57,  0.27it/s, v_num=2, train_loss_step=16.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:06<01:57,  0.27it/s, v_num=2, train_loss_step=17.70, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:10<01:54,  0.27it/s, v_num=2, train_loss_step=17.70, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:10<01:54,  0.27it/s, v_num=2, train_loss_step=16.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:14<01:51,  0.27it/s, v_num=2, train_loss_step=16.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:14<01:51,  0.27it/s, v_num=2, train_loss_step=15.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:18<01:47,  0.27it/s, v_num=2, train_loss_step=15.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:18<01:47,  0.27it/s, v_num=2, train_loss_step=13.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:21<01:44,  0.27it/s, v_num=2, train_loss_step=13.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:21<01:44,  0.27it/s, v_num=2, train_loss_step=16.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:24<01:39,  0.27it/s, v_num=2, train_loss_step=16.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:24<01:39,  0.27it/s, v_num=2, train_loss_step=15.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:27<01:35,  0.27it/s, v_num=2, train_loss_step=15.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:27<01:35,  0.27it/s, v_num=2, train_loss_step=15.00, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:31<01:31,  0.27it/s, v_num=2, train_loss_step=15.00, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:31<01:31,  0.27it/s, v_num=2, train_loss_step=14.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:34<01:27,  0.27it/s, v_num=2, train_loss_step=14.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:34<01:27,  0.27it/s, v_num=2, train_loss_step=15.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:37<01:23,  0.28it/s, v_num=2, train_loss_step=15.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:37<01:23,  0.28it/s, v_num=2, train_loss_step=15.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:40<01:19,  0.28it/s, v_num=2, train_loss_step=15.90, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:40<01:19,  0.28it/s, v_num=2, train_loss_step=14.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:44<01:15,  0.28it/s, v_num=2, train_loss_step=14.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:44<01:15,  0.28it/s, v_num=2, train_loss_step=14.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:47<01:11,  0.28it/s, v_num=2, train_loss_step=14.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:47<01:11,  0.28it/s, v_num=2, train_loss_step=14.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:50<01:07,  0.28it/s, v_num=2, train_loss_step=14.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:50<01:07,  0.28it/s, v_num=2, train_loss_step=14.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:53<01:04,  0.28it/s, v_num=2, train_loss_step=14.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:53<01:04,  0.28it/s, v_num=2, train_loss_step=14.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:56<01:00,  0.28it/s, v_num=2, train_loss_step=14.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:56<01:00,  0.28it/s, v_num=2, train_loss_step=14.00, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:00<00:56,  0.28it/s, v_num=2, train_loss_step=14.00, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:00<00:56,  0.28it/s, v_num=2, train_loss_step=14.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:03<00:52,  0.28it/s, v_num=2, train_loss_step=14.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:03<00:52,  0.28it/s, v_num=2, train_loss_step=14.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:05<00:48,  0.29it/s, v_num=2, train_loss_step=14.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:05<00:48,  0.29it/s, v_num=2, train_loss_step=13.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:08<00:45,  0.29it/s, v_num=2, train_loss_step=13.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:08<00:45,  0.29it/s, v_num=2, train_loss_step=13.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:12<00:41,  0.29it/s, v_num=2, train_loss_step=13.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:12<00:41,  0.29it/s, v_num=2, train_loss_step=14.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:15<00:38,  0.29it/s, v_num=2, train_loss_step=14.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:15<00:38,  0.29it/s, v_num=2, train_loss_step=14.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:18<00:34,  0.29it/s, v_num=2, train_loss_step=14.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:18<00:34,  0.29it/s, v_num=2, train_loss_step=13.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:20<00:30,  0.29it/s, v_num=2, train_loss_step=13.50, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:20<00:30,  0.29it/s, v_num=2, train_loss_step=12.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:24<00:27,  0.29it/s, v_num=2, train_loss_step=12.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:24<00:27,  0.29it/s, v_num=2, train_loss_step=15.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:27<00:23,  0.29it/s, v_num=2, train_loss_step=15.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:27<00:23,  0.29it/s, v_num=2, train_loss_step=13.00, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:30<00:20,  0.29it/s, v_num=2, train_loss_step=13.00, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:30<00:20,  0.29it/s, v_num=2, train_loss_step=14.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:33<00:17,  0.29it/s, v_num=2, train_loss_step=14.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:33<00:17,  0.29it/s, v_num=2, train_loss_step=12.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:36<00:13,  0.29it/s, v_num=2, train_loss_step=12.10, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:36<00:13,  0.29it/s, v_num=2, train_loss_step=12.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:40<00:10,  0.29it/s, v_num=2, train_loss_step=12.80, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:40<00:10,  0.29it/s, v_num=2, train_loss_step=11.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:42<00:06,  0.29it/s, v_num=2, train_loss_step=11.30, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:42<00:06,  0.29it/s, v_num=2, train_loss_step=14.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:47<00:03,  0.29it/s, v_num=2, train_loss_step=14.40, val_loss=10.90, train_loss_epoch=31.40]Epoch 2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:47<00:03,  0.29it/s, v_num=2, train_loss_step=13.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:51<00:00,  0.29it/s, v_num=2, train_loss_step=13.60, val_loss=10.90, train_loss_epoch=31.40]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:51<00:00,  0.29it/s, v_num=2, train_loss_step=11.20, val_loss=10.90, train_loss_epoch=31.40]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  0.51it/s][A
                                                                      [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:55<00:00,  0.29it/s, v_num=2, train_loss_step=11.20, val_loss=7.460, train_loss_epoch=31.40]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:55<00:00,  0.29it/s, v_num=2, train_loss_step=11.20, val_loss=7.460, train_loss_epoch=15.70]Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=11.20, val_loss=7.460, train_loss_epoch=15.70]         Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=11.20, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   2%|â–         | 1/50 [00:03<03:02,  0.27it/s, v_num=2, train_loss_step=11.20, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   2%|â–         | 1/50 [00:03<03:03,  0.27it/s, v_num=2, train_loss_step=10.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   4%|â–         | 2/50 [00:07<03:07,  0.26it/s, v_num=2, train_loss_step=10.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   4%|â–         | 2/50 [00:07<03:07,  0.26it/s, v_num=2, train_loss_step=16.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   6%|â–Œ         | 3/50 [00:12<03:11,  0.25it/s, v_num=2, train_loss_step=16.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   6%|â–Œ         | 3/50 [00:12<03:11,  0.25it/s, v_num=2, train_loss_step=14.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   8%|â–Š         | 4/50 [00:16<03:07,  0.25it/s, v_num=2, train_loss_step=14.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:   8%|â–Š         | 4/50 [00:16<03:07,  0.25it/s, v_num=2, train_loss_step=9.230, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  10%|â–ˆ         | 5/50 [00:21<03:09,  0.24it/s, v_num=2, train_loss_step=9.230, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  10%|â–ˆ         | 5/50 [00:21<03:09,  0.24it/s, v_num=2, train_loss_step=8.310, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  12%|â–ˆâ–        | 6/50 [00:25<03:05,  0.24it/s, v_num=2, train_loss_step=8.310, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  12%|â–ˆâ–        | 6/50 [00:25<03:05,  0.24it/s, v_num=2, train_loss_step=17.90, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  14%|â–ˆâ–        | 7/50 [00:28<02:53,  0.25it/s, v_num=2, train_loss_step=17.90, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  14%|â–ˆâ–        | 7/50 [00:28<02:53,  0.25it/s, v_num=2, train_loss_step=16.30, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  16%|â–ˆâ–Œ        | 8/50 [00:32<02:49,  0.25it/s, v_num=2, train_loss_step=16.30, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  16%|â–ˆâ–Œ        | 8/50 [00:32<02:49,  0.25it/s, v_num=2, train_loss_step=8.230, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  18%|â–ˆâ–Š        | 9/50 [00:35<02:42,  0.25it/s, v_num=2, train_loss_step=8.230, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  18%|â–ˆâ–Š        | 9/50 [00:35<02:42,  0.25it/s, v_num=2, train_loss_step=8.490, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  20%|â–ˆâ–ˆ        | 10/50 [00:38<02:34,  0.26it/s, v_num=2, train_loss_step=8.490, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  20%|â–ˆâ–ˆ        | 10/50 [00:38<02:34,  0.26it/s, v_num=2, train_loss_step=18.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  22%|â–ˆâ–ˆâ–       | 11/50 [00:42<02:29,  0.26it/s, v_num=2, train_loss_step=18.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  22%|â–ˆâ–ˆâ–       | 11/50 [00:42<02:29,  0.26it/s, v_num=2, train_loss_step=15.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  24%|â–ˆâ–ˆâ–       | 12/50 [00:45<02:22,  0.27it/s, v_num=2, train_loss_step=15.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  24%|â–ˆâ–ˆâ–       | 12/50 [00:45<02:22,  0.27it/s, v_num=2, train_loss_step=9.600, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:47<02:16,  0.27it/s, v_num=2, train_loss_step=9.600, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:47<02:16,  0.27it/s, v_num=2, train_loss_step=9.110, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:51<02:12,  0.27it/s, v_num=2, train_loss_step=9.110, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  28%|â–ˆâ–ˆâ–Š       | 14/50 [00:51<02:12,  0.27it/s, v_num=2, train_loss_step=10.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:55<02:10,  0.27it/s, v_num=2, train_loss_step=10.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:55<02:10,  0.27it/s, v_num=2, train_loss_step=7.570, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:58<02:05,  0.27it/s, v_num=2, train_loss_step=7.570, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:58<02:05,  0.27it/s, v_num=2, train_loss_step=15.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [01:03<02:02,  0.27it/s, v_num=2, train_loss_step=15.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [01:03<02:02,  0.27it/s, v_num=2, train_loss_step=14.90, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:06<01:57,  0.27it/s, v_num=2, train_loss_step=14.90, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:06<01:57,  0.27it/s, v_num=2, train_loss_step=7.710, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:08<01:51,  0.28it/s, v_num=2, train_loss_step=7.710, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:08<01:51,  0.28it/s, v_num=2, train_loss_step=10.90, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:12<01:48,  0.28it/s, v_num=2, train_loss_step=10.90, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:12<01:48,  0.28it/s, v_num=2, train_loss_step=7.390, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:14<01:43,  0.28it/s, v_num=2, train_loss_step=7.390, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:15<01:43,  0.28it/s, v_num=2, train_loss_step=6.440, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:17<01:38,  0.28it/s, v_num=2, train_loss_step=6.440, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:17<01:38,  0.28it/s, v_num=2, train_loss_step=15.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:20<01:34,  0.29it/s, v_num=2, train_loss_step=15.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:20<01:34,  0.29it/s, v_num=2, train_loss_step=10.70, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:23<01:30,  0.29it/s, v_num=2, train_loss_step=10.70, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:23<01:30,  0.29it/s, v_num=2, train_loss_step=16.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:27<01:27,  0.29it/s, v_num=2, train_loss_step=16.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:27<01:27,  0.29it/s, v_num=2, train_loss_step=19.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:30<01:23,  0.29it/s, v_num=2, train_loss_step=19.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [01:30<01:23,  0.29it/s, v_num=2, train_loss_step=8.000, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:34<01:20,  0.29it/s, v_num=2, train_loss_step=8.000, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [01:34<01:20,  0.29it/s, v_num=2, train_loss_step=13.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:38<01:17,  0.28it/s, v_num=2, train_loss_step=13.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [01:38<01:17,  0.28it/s, v_num=2, train_loss_step=8.280, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:41<01:13,  0.29it/s, v_num=2, train_loss_step=8.280, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [01:41<01:13,  0.29it/s, v_num=2, train_loss_step=8.890, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:46<01:10,  0.28it/s, v_num=2, train_loss_step=8.890, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:46<01:10,  0.28it/s, v_num=2, train_loss_step=7.420, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:49<01:07,  0.28it/s, v_num=2, train_loss_step=7.420, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [01:49<01:07,  0.28it/s, v_num=2, train_loss_step=8.420, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:52<01:03,  0.28it/s, v_num=2, train_loss_step=8.420, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:52<01:03,  0.28it/s, v_num=2, train_loss_step=5.630, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:57<01:00,  0.28it/s, v_num=2, train_loss_step=5.630, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:57<01:00,  0.28it/s, v_num=2, train_loss_step=15.70, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:01<00:57,  0.28it/s, v_num=2, train_loss_step=15.70, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:01<00:57,  0.28it/s, v_num=2, train_loss_step=14.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:05<00:53,  0.28it/s, v_num=2, train_loss_step=14.60, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:05<00:53,  0.28it/s, v_num=2, train_loss_step=5.280, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:09<00:50,  0.28it/s, v_num=2, train_loss_step=5.280, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:09<00:50,  0.28it/s, v_num=2, train_loss_step=7.650, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:12<00:46,  0.28it/s, v_num=2, train_loss_step=7.650, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:12<00:46,  0.28it/s, v_num=2, train_loss_step=5.900, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:16<00:43,  0.28it/s, v_num=2, train_loss_step=5.900, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [02:16<00:43,  0.28it/s, v_num=2, train_loss_step=5.590, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:19<00:39,  0.28it/s, v_num=2, train_loss_step=5.590, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [02:19<00:39,  0.28it/s, v_num=2, train_loss_step=10.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:23<00:35,  0.28it/s, v_num=2, train_loss_step=10.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [02:23<00:35,  0.28it/s, v_num=2, train_loss_step=5.820, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:27<00:32,  0.28it/s, v_num=2, train_loss_step=5.820, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [02:27<00:32,  0.28it/s, v_num=2, train_loss_step=28.20, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:30<00:28,  0.28it/s, v_num=2, train_loss_step=28.20, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [02:30<00:28,  0.28it/s, v_num=2, train_loss_step=36.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:33<00:25,  0.28it/s, v_num=2, train_loss_step=36.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [02:33<00:25,  0.28it/s, v_num=2, train_loss_step=9.430, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:37<00:21,  0.28it/s, v_num=2, train_loss_step=9.430, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [02:37<00:21,  0.28it/s, v_num=2, train_loss_step=29.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:40<00:17,  0.28it/s, v_num=2, train_loss_step=29.50, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:40<00:17,  0.28it/s, v_num=2, train_loss_step=54.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:44<00:14,  0.28it/s, v_num=2, train_loss_step=54.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [02:44<00:14,  0.28it/s, v_num=2, train_loss_step=28.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:47<00:10,  0.28it/s, v_num=2, train_loss_step=28.10, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [02:47<00:10,  0.28it/s, v_num=2, train_loss_step=9.430, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:51<00:07,  0.28it/s, v_num=2, train_loss_step=9.430, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [02:51<00:07,  0.28it/s, v_num=2, train_loss_step=26.80, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:55<00:03,  0.28it/s, v_num=2, train_loss_step=26.80, val_loss=7.460, train_loss_epoch=15.70]Epoch 3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [02:55<00:03,  0.28it/s, v_num=2, train_loss_step=25.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:59<00:00,  0.28it/s, v_num=2, train_loss_step=25.00, val_loss=7.460, train_loss_epoch=15.70]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:59<00:00,  0.28it/s, v_num=2, train_loss_step=5.930, val_loss=7.460, train_loss_epoch=15.70]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  0.57it/s][A
                                                                      [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:01<00:00,  0.27it/s, v_num=2, train_loss_step=5.930, val_loss=24.40, train_loss_epoch=15.70]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:01<00:00,  0.27it/s, v_num=2, train_loss_step=5.930, val_loss=24.40, train_loss_epoch=13.70]Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=5.930, val_loss=24.40, train_loss_epoch=13.70]         Epoch 4:   0%|          | 0/50 [00:00<?, ?it/s, v_num=2, train_loss_step=5.930, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   2%|â–         | 1/50 [00:04<03:28,  0.23it/s, v_num=2, train_loss_step=5.930, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   2%|â–         | 1/50 [00:04<03:28,  0.23it/s, v_num=2, train_loss_step=28.20, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   4%|â–         | 2/50 [00:06<02:40,  0.30it/s, v_num=2, train_loss_step=28.20, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   4%|â–         | 2/50 [00:06<02:40,  0.30it/s, v_num=2, train_loss_step=45.40, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   6%|â–Œ         | 3/50 [00:09<02:32,  0.31it/s, v_num=2, train_loss_step=45.40, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   6%|â–Œ         | 3/50 [00:09<02:32,  0.31it/s, v_num=2, train_loss_step=20.60, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   8%|â–Š         | 4/50 [00:13<02:34,  0.30it/s, v_num=2, train_loss_step=20.60, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:   8%|â–Š         | 4/50 [00:13<02:34,  0.30it/s, v_num=2, train_loss_step=11.50, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  10%|â–ˆ         | 5/50 [00:17<02:36,  0.29it/s, v_num=2, train_loss_step=11.50, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  10%|â–ˆ         | 5/50 [00:17<02:36,  0.29it/s, v_num=2, train_loss_step=23.70, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  12%|â–ˆâ–        | 6/50 [00:31<03:49,  0.19it/s, v_num=2, train_loss_step=23.70, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  12%|â–ˆâ–        | 6/50 [00:31<03:49,  0.19it/s, v_num=2, train_loss_step=15.40, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  14%|â–ˆâ–        | 7/50 [00:38<03:57,  0.18it/s, v_num=2, train_loss_step=15.40, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  14%|â–ˆâ–        | 7/50 [00:38<03:57,  0.18it/s, v_num=2, train_loss_step=10.50, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  16%|â–ˆâ–Œ        | 8/50 [00:43<03:48,  0.18it/s, v_num=2, train_loss_step=10.50, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  16%|â–ˆâ–Œ        | 8/50 [00:43<03:48,  0.18it/s, v_num=2, train_loss_step=17.40, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  18%|â–ˆâ–Š        | 9/50 [00:48<03:38,  0.19it/s, v_num=2, train_loss_step=17.40, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  18%|â–ˆâ–Š        | 9/50 [00:48<03:38,  0.19it/s, v_num=2, train_loss_step=13.10, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  20%|â–ˆâ–ˆ        | 10/50 [00:51<03:24,  0.20it/s, v_num=2, train_loss_step=13.10, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  20%|â–ˆâ–ˆ        | 10/50 [00:51<03:24,  0.20it/s, v_num=2, train_loss_step=7.100, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  22%|â–ˆâ–ˆâ–       | 11/50 [00:56<03:21,  0.19it/s, v_num=2, train_loss_step=7.100, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  22%|â–ˆâ–ˆâ–       | 11/50 [00:56<03:21,  0.19it/s, v_num=2, train_loss_step=15.80, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  24%|â–ˆâ–ˆâ–       | 12/50 [01:01<03:14,  0.20it/s, v_num=2, train_loss_step=15.80, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  24%|â–ˆâ–ˆâ–       | 12/50 [01:01<03:14,  0.20it/s, v_num=2, train_loss_step=9.360, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [01:05<03:06,  0.20it/s, v_num=2, train_loss_step=9.360, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [01:05<03:06,  0.20it/s, v_num=2, train_loss_step=8.950, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  28%|â–ˆâ–ˆâ–Š       | 14/50 [01:09<02:59,  0.20it/s, v_num=2, train_loss_step=8.950, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  28%|â–ˆâ–ˆâ–Š       | 14/50 [01:09<02:59,  0.20it/s, v_num=2, train_loss_step=9.400, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [01:13<02:50,  0.21it/s, v_num=2, train_loss_step=9.400, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [01:13<02:50,  0.21it/s, v_num=2, train_loss_step=6.720, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [01:17<02:44,  0.21it/s, v_num=2, train_loss_step=6.720, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [01:17<02:44,  0.21it/s, v_num=2, train_loss_step=6.900, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [01:21<02:37,  0.21it/s, v_num=2, train_loss_step=6.900, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [01:21<02:37,  0.21it/s, v_num=2, train_loss_step=8.950, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:24<02:31,  0.21it/s, v_num=2, train_loss_step=8.950, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [01:24<02:31,  0.21it/s, v_num=2, train_loss_step=8.510, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:30<02:26,  0.21it/s, v_num=2, train_loss_step=8.510, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [01:30<02:26,  0.21it/s, v_num=2, train_loss_step=9.280, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:33<02:20,  0.21it/s, v_num=2, train_loss_step=9.280, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [01:33<02:20,  0.21it/s, v_num=2, train_loss_step=9.470, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:38<02:15,  0.21it/s, v_num=2, train_loss_step=9.470, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [01:38<02:15,  0.21it/s, v_num=2, train_loss_step=8.450, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:44<02:12,  0.21it/s, v_num=2, train_loss_step=8.450, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [01:44<02:12,  0.21it/s, v_num=2, train_loss_step=7.570, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:48<02:07,  0.21it/s, v_num=2, train_loss_step=7.570, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [01:48<02:07,  0.21it/s, v_num=2, train_loss_step=8.410, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:53<02:02,  0.21it/s, v_num=2, train_loss_step=8.410, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [01:53<02:02,  0.21it/s, v_num=2, train_loss_step=7.410, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:57<01:57,  0.21it/s, v_num=2, train_loss_step=7.410, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:57<01:57,  0.21it/s, v_num=2, train_loss_step=7.100, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [02:03<01:53,  0.21it/s, v_num=2, train_loss_step=7.100, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [02:03<01:53,  0.21it/s, v_num=2, train_loss_step=6.070, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [02:08<01:49,  0.21it/s, v_num=2, train_loss_step=6.070, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [02:08<01:49,  0.21it/s, v_num=2, train_loss_step=7.610, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [02:12<01:44,  0.21it/s, v_num=2, train_loss_step=7.610, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [02:12<01:44,  0.21it/s, v_num=2, train_loss_step=6.990, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [02:19<01:40,  0.21it/s, v_num=2, train_loss_step=6.990, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [02:19<01:40,  0.21it/s, v_num=2, train_loss_step=6.970, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [02:24<01:36,  0.21it/s, v_num=2, train_loss_step=6.970, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [02:24<01:36,  0.21it/s, v_num=2, train_loss_step=6.630, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [02:29<01:31,  0.21it/s, v_num=2, train_loss_step=6.630, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [02:29<01:31,  0.21it/s, v_num=2, train_loss_step=7.680, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [02:34<01:26,  0.21it/s, v_num=2, train_loss_step=7.680, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [02:34<01:26,  0.21it/s, v_num=2, train_loss_step=6.370, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [02:38<01:21,  0.21it/s, v_num=2, train_loss_step=6.370, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [02:38<01:21,  0.21it/s, v_num=2, train_loss_step=8.170, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:43<01:17,  0.21it/s, v_num=2, train_loss_step=8.170, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [02:43<01:17,  0.21it/s, v_num=2, train_loss_step=7.050, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:47<01:11,  0.21it/s, v_num=2, train_loss_step=7.050, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [02:47<01:11,  0.21it/s, v_num=2, train_loss_step=6.940, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:52<01:07,  0.21it/s, v_num=2, train_loss_step=6.940, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [02:52<01:07,  0.21it/s, v_num=2, train_loss_step=5.720, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:55<01:01,  0.21it/s, v_num=2, train_loss_step=5.720, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [02:55<01:01,  0.21it/s, v_num=2, train_loss_step=7.370, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [03:00<00:56,  0.21it/s, v_num=2, train_loss_step=7.370, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [03:00<00:57,  0.21it/s, v_num=2, train_loss_step=6.390, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [03:05<00:52,  0.21it/s, v_num=2, train_loss_step=6.390, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [03:05<00:52,  0.21it/s, v_num=2, train_loss_step=7.290, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [03:08<00:47,  0.21it/s, v_num=2, train_loss_step=7.290, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [03:08<00:47,  0.21it/s, v_num=2, train_loss_step=6.920, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [03:12<00:42,  0.21it/s, v_num=2, train_loss_step=6.920, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [03:12<00:42,  0.21it/s, v_num=2, train_loss_step=6.460, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [03:16<00:37,  0.21it/s, v_num=2, train_loss_step=6.460, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [03:16<00:37,  0.21it/s, v_num=2, train_loss_step=6.490, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [03:20<00:32,  0.21it/s, v_num=2, train_loss_step=6.490, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [03:20<00:32,  0.21it/s, v_num=2, train_loss_step=6.860, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [03:24<00:27,  0.21it/s, v_num=2, train_loss_step=6.860, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [03:24<00:27,  0.21it/s, v_num=2, train_loss_step=6.750, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [03:29<00:23,  0.21it/s, v_num=2, train_loss_step=6.750, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [03:29<00:23,  0.21it/s, v_num=2, train_loss_step=6.510, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [03:35<00:18,  0.21it/s, v_num=2, train_loss_step=6.510, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [03:35<00:18,  0.21it/s, v_num=2, train_loss_step=5.640, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [03:40<00:14,  0.21it/s, v_num=2, train_loss_step=5.640, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [03:40<00:14,  0.21it/s, v_num=2, train_loss_step=6.600, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [03:45<00:09,  0.21it/s, v_num=2, train_loss_step=6.600, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [03:45<00:09,  0.21it/s, v_num=2, train_loss_step=5.550, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [03:47<00:04,  0.22it/s, v_num=2, train_loss_step=5.550, val_loss=24.40, train_loss_epoch=13.70]Epoch 4:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [03:47<00:04,  0.22it/s, v_num=2, train_loss_step=6.670, val_loss=24.40, train_loss_epoch=13.70]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:50<00:00,  0.22it/s, v_num=2, train_loss_step=6.670, val_loss=24.40, train_loss_epoch=13.70]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:50<00:00,  0.22it/s, v_num=2, train_loss_step=5.970, val_loss=24.40, train_loss_epoch=13.70]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  0.44it/s][A
                                                                      [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:54<00:00,  0.21it/s, v_num=2, train_loss_step=5.970, val_loss=4.860, train_loss_epoch=13.70]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:54<00:00,  0.21it/s, v_num=2, train_loss_step=5.970, val_loss=4.860, train_loss_epoch=9.860]`Trainer.fit` stopped: `max_epochs=5` reached.
Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:55<00:00,  0.21it/s, v_num=2, train_loss_step=5.970, val_loss=4.860, train_loss_epoch=9.860] * Detected change in '/Users/amirrezasokhankhosh/Documents/Workstation/DigitalTwin/nodes/aggregator.py', reloading

 * Restarting with stat
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/Users/amirrezasokhankhosh/mambaforge/envs/flask/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
 * Debugger is active!
 * Debugger PIN: 868-625-521
