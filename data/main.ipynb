{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import MultiNormalizer, EncoderNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import (\n",
    "    optimize_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\".*does not have valid feature names.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ac32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./rooms/F1_R1.csv\"\n",
    "\n",
    "max_encoder_length = 48\n",
    "max_prediction_length = 5\n",
    "\n",
    "lr = 3e-4\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df[\"hour\"] = df[\"hour\"].astype(str)\n",
    "df[\"day\"] = df[\"day\"].astype(str)\n",
    "df[\"month\"] = df[\"month\"].astype(str)\n",
    "df = df.sort_values([\"room_id\", \"timestamp\"]).reset_index(drop=True)\n",
    "df[\"time_idx\"] = df.groupby(\"room_id\").cumcount()\n",
    "training_cutoff = df[\"time_idx\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"humidity\", \"temperature\", \"co2\", \"electricity\"],\n",
    "    group_ids=[\"room_id\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"room_id\"],\n",
    "    static_reals=[\"area\", \"num_windows\", \"window_area\"],\n",
    "    time_varying_known_categoricals=[\"hour\", \"day\", \"month\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\"humidity\", \"temperature\", \"co2\", \"electricity\"],\n",
    "    target_normalizer=MultiNormalizer([\n",
    "        EncoderNormalizer(method='standard',center=True,max_length=None,transformation=None,method_kwargs={}),\n",
    "        EncoderNormalizer(method='standard',center=True,max_length=None,transformation=None,method_kwargs={}),\n",
    "        EncoderNormalizer(method='standard',center=True,max_length=None,transformation=None,method_kwargs={}),\n",
    "        EncoderNormalizer(method='standard',center=True,max_length=None,transformation=None,method_kwargs={})\n",
    "    ]),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    train_dataset, df, predict=True, stop_randomization=True\n",
    ")\n",
    "val_dataloader = val_dataset.to_dataloader(\n",
    "    train=False, batch_size=batch_size * 10, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a97b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataset.to_dataloader(batch_size=4)))\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predictions = Baseline().predict(val_dataloader, return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b86fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"humidity\", \"temperature\", \"co2\", \"electricity\"]\n",
    "outputs = baseline_predictions.output\n",
    "y = baseline_predictions.y\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    print(f\"{targets[i]}: {MAE()(outputs[i], y[0][i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985582b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=lr,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    loss=MAE(),\n",
    "    output_size=[1, 1, 1, 1],\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in network: {model.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    gradient_clip_val=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e235c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Tuner(trainer).lr_find(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca464a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\"\n",
    ")\n",
    "lr_logger = LearningRateMonitor()\n",
    "logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
